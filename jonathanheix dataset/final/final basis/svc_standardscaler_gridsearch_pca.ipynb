{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pickle import dump, load\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(images_folder, save_file_to=None):\n",
    "    \n",
    "    X_original = []\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(images_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(('jpg', 'jpeg', 'png')):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                label = os.path.basename(subdir)\n",
    "                \n",
    "                image = Image.open(img_path).convert('L')\n",
    "                image = image.resize((48, 48))\n",
    "                X_original.append(np.array(image).flatten())\n",
    "                X.append(np.array(image).flatten())\n",
    "                y.append(label)\n",
    "                \n",
    "    if save_file_to:\n",
    "        with open(save_file_to, \"wb\") as f:\n",
    "            dump((X_original, X, y), f, protocol=5)\n",
    "                \n",
    "    return np.array(X_original), np.array(X), np.array(y)\n",
    "\n",
    "images_folder = '/Users/shaneab/Projects/Machine Learning/Expression recognition/jonathanheix dataset/images'\n",
    "dataset_file = \"dataset_dump.pkl\"\n",
    "\n",
    "# Load images and save the dataset for reuse\n",
    "X_original, X, y = load_images(images_folder, save_file_to=dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"dataset_dump.pkl\", \"rb\") as f:\n",
    "    X_original,X,y = load(f)\n",
    "    \n",
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(X, y, save_file_to=None):\n",
    "    # Normalize pixel values\n",
    "    X = X / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    # Dimensionality reduction with PCA\n",
    "    pca = PCA(n_components=100)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_reduced)\n",
    "    \n",
    "    if save_file_to:\n",
    "        with open(save_file_to, \"wb\") as f:\n",
    "            dump((X_scaled, y_encoded, label_encoder, pca, scaler), f, protocol=5)\n",
    "    \n",
    "    return X_scaled, y_encoded, label_encoder, pca, scaler\n",
    "\n",
    "X_scaled, y_encoded, label_encoder, pca, scaler = preprocessing_data(X, y, save_file_to=\"labelencoder_standardscaler_pca_normalizers_dump.pkl\")\n",
    "\n",
    "# with open(\"svc_standardscaler_gridsearch_normalizers_dump.pkl\", \"wb\") as f:\n",
    "#     dump((label_encoder, pca, scaler), f, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labelencoder_standardscaler_pca_normalizers_dump.pkl\", \"rb\") as f:\n",
    "    X_scaled, y_encoded, label_encoder, pca, scaler = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'degree': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 1, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.08      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.27      0.11      0.15      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.35      0.34      0.34      1260\n",
      "         sad       0.31      0.33      0.32      1226\n",
      "    surprise       0.52      0.38      0.44       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.31      0.29      0.27      7178\n",
      "weighted avg       0.35      0.38      0.34      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.29      0.08      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.15      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.31      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.34      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.08      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.27      0.11      0.15      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.35      0.34      0.34      1260\n",
      "         sad       0.31      0.33      0.32      1226\n",
      "    surprise       0.52      0.38      0.44       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.31      0.29      0.27      7178\n",
      "weighted avg       0.35      0.38      0.34      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.30      0.08      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.14      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.35      0.34      0.34      1260\n",
      "         sad       0.30      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.35      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.52      0.03      0.05       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.65      0.03      0.06      1015\n",
      "       happy       0.27      0.98      0.42      1824\n",
      "     neutral       0.36      0.02      0.03      1260\n",
      "         sad       0.38      0.08      0.13      1226\n",
      "    surprise       0.87      0.13      0.23       776\n",
      "\n",
      "    accuracy                           0.29      7178\n",
      "   macro avg       0.44      0.18      0.13      7178\n",
      "weighted avg       0.45      0.29      0.18      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 2, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.29      0.08      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.15      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.31      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.34      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 2, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.52      0.03      0.05       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.65      0.03      0.06      1015\n",
      "       happy       0.27      0.98      0.42      1824\n",
      "     neutral       0.35      0.02      0.03      1260\n",
      "         sad       0.38      0.08      0.13      1226\n",
      "    surprise       0.87      0.13      0.23       776\n",
      "\n",
      "    accuracy                           0.29      7178\n",
      "   macro avg       0.43      0.18      0.13      7178\n",
      "weighted avg       0.45      0.29      0.18      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.30      0.08      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.14      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.35      0.34      0.34      1260\n",
      "         sad       0.30      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.35      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.86      0.02      0.04       970\n",
      "     disgust       1.00      0.01      0.02       107\n",
      "        fear       0.86      0.02      0.03      1015\n",
      "       happy       0.26      1.00      0.41      1824\n",
      "     neutral       0.33      0.00      0.00      1260\n",
      "         sad       0.83      0.02      0.03      1226\n",
      "    surprise       0.95      0.05      0.10       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.73      0.16      0.09      7178\n",
      "weighted avg       0.62      0.27      0.13      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 3, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.29      0.08      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.15      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.31      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.34      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 3, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.86      0.02      0.04       970\n",
      "     disgust       1.00      0.01      0.02       107\n",
      "        fear       0.86      0.02      0.03      1015\n",
      "       happy       0.26      1.00      0.41      1824\n",
      "     neutral       0.33      0.00      0.00      1260\n",
      "         sad       0.83      0.02      0.03      1226\n",
      "    surprise       0.95      0.05      0.10       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.73      0.16      0.09      7178\n",
      "weighted avg       0.62      0.27      0.13      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 3, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.30      0.08      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.14      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.35      0.34      0.34      1260\n",
      "         sad       0.30      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.35      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 4, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.85      0.02      0.04       970\n",
      "     disgust       1.00      0.03      0.05       107\n",
      "        fear       0.82      0.03      0.06      1015\n",
      "       happy       0.26      1.00      0.41      1824\n",
      "     neutral       0.55      0.00      0.01      1260\n",
      "         sad       0.74      0.02      0.04      1226\n",
      "    surprise       0.94      0.04      0.07       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.74      0.16      0.10      7178\n",
      "weighted avg       0.63      0.27      0.14      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 4, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.29      0.08      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.15      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.31      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.34      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 4, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.85      0.02      0.04       970\n",
      "     disgust       1.00      0.03      0.05       107\n",
      "        fear       0.82      0.03      0.06      1015\n",
      "       happy       0.26      1.00      0.41      1824\n",
      "     neutral       0.50      0.00      0.01      1260\n",
      "         sad       0.74      0.02      0.04      1226\n",
      "    surprise       0.94      0.04      0.07       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.73      0.16      0.10      7178\n",
      "weighted avg       0.63      0.27      0.14      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 4, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.30      0.08      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.14      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.35      0.34      0.34      1260\n",
      "         sad       0.30      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.35      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 5, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.88      0.02      0.05       970\n",
      "     disgust       1.00      0.03      0.05       107\n",
      "        fear       0.82      0.03      0.06      1015\n",
      "       happy       0.26      1.00      0.41      1824\n",
      "     neutral       0.62      0.00      0.01      1260\n",
      "         sad       0.90      0.01      0.03      1226\n",
      "    surprise       1.00      0.04      0.08       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.78      0.16      0.10      7178\n",
      "weighted avg       0.69      0.27      0.13      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 5, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.29      0.08      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.15      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.31      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.34      0.37      0.33      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 5, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.64      0.02      0.04       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.35      0.04      0.07      1015\n",
      "       happy       0.36      0.87      0.51      1824\n",
      "     neutral       0.39      0.31      0.34      1260\n",
      "         sad       0.30      0.31      0.31      1226\n",
      "    surprise       0.71      0.31      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.26      0.24      7178\n",
      "weighted avg       0.42      0.37      0.30      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.88      0.02      0.05       970\n",
      "     disgust       1.00      0.03      0.05       107\n",
      "        fear       0.82      0.03      0.06      1015\n",
      "       happy       0.26      1.00      0.41      1824\n",
      "     neutral       0.62      0.00      0.01      1260\n",
      "         sad       0.90      0.01      0.03      1226\n",
      "    surprise       1.00      0.04      0.08       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.78      0.16      0.10      7178\n",
      "weighted avg       0.69      0.27      0.13      7178\n",
      "\n",
      "{'C': 0.1, 'degree': 5, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.30      0.08      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.10      0.14      1015\n",
      "       happy       0.41      0.76      0.53      1824\n",
      "     neutral       0.35      0.34      0.34      1260\n",
      "         sad       0.30      0.32      0.31      1226\n",
      "    surprise       0.50      0.37      0.43       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.30      0.28      0.27      7178\n",
      "weighted avg       0.35      0.37      0.33      7178\n",
      "\n",
      "{'C': 1, 'degree': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.28      0.12      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.26      0.13      0.17      1015\n",
      "       happy       0.44      0.71      0.54      1824\n",
      "     neutral       0.35      0.36      0.35      1260\n",
      "         sad       0.30      0.33      0.31      1226\n",
      "    surprise       0.50      0.43      0.46       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.31      0.30      0.29      7178\n",
      "weighted avg       0.35      0.38      0.35      7178\n",
      "\n",
      "{'C': 1, 'degree': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.12      0.15      1015\n",
      "       happy       0.42      0.67      0.52      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.28      0.12      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.26      0.13      0.17      1015\n",
      "       happy       0.44      0.71      0.54      1824\n",
      "     neutral       0.35      0.36      0.35      1260\n",
      "         sad       0.30      0.32      0.31      1226\n",
      "    surprise       0.50      0.43      0.46       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.31      0.30      0.29      7178\n",
      "weighted avg       0.35      0.38      0.35      7178\n",
      "\n",
      "{'C': 1, 'degree': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.11      0.14      1015\n",
      "       happy       0.43      0.67      0.52      1824\n",
      "     neutral       0.33      0.34      0.33      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.40\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.23      0.26       970\n",
      "     disgust       0.77      0.09      0.17       107\n",
      "        fear       0.33      0.22      0.27      1015\n",
      "       happy       0.42      0.70      0.53      1824\n",
      "     neutral       0.36      0.35      0.36      1260\n",
      "         sad       0.33      0.27      0.29      1226\n",
      "    surprise       0.65      0.44      0.52       776\n",
      "\n",
      "    accuracy                           0.40      7178\n",
      "   macro avg       0.45      0.33      0.34      7178\n",
      "weighted avg       0.40      0.40      0.38      7178\n",
      "\n",
      "{'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.12      0.15      1015\n",
      "       happy       0.42      0.67      0.52      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 2, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.40\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.23      0.26       970\n",
      "     disgust       0.77      0.09      0.17       107\n",
      "        fear       0.33      0.22      0.27      1015\n",
      "       happy       0.42      0.70      0.53      1824\n",
      "     neutral       0.36      0.35      0.36      1260\n",
      "         sad       0.33      0.27      0.29      1226\n",
      "    surprise       0.65      0.44      0.52       776\n",
      "\n",
      "    accuracy                           0.40      7178\n",
      "   macro avg       0.45      0.33      0.34      7178\n",
      "weighted avg       0.40      0.40      0.38      7178\n",
      "\n",
      "{'C': 1, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.11      0.14      1015\n",
      "       happy       0.43      0.67      0.52      1824\n",
      "     neutral       0.33      0.34      0.33      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.14      0.23       970\n",
      "     disgust       1.00      0.09      0.17       107\n",
      "        fear       0.62      0.18      0.28      1015\n",
      "       happy       0.34      0.92      0.49      1824\n",
      "     neutral       0.44      0.26      0.33      1260\n",
      "         sad       0.48      0.19      0.28      1226\n",
      "    surprise       0.78      0.44      0.56       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.61      0.32      0.33      7178\n",
      "weighted avg       0.51      0.41      0.36      7178\n",
      "\n",
      "{'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.12      0.15      1015\n",
      "       happy       0.42      0.67      0.52      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 3, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.14      0.23       970\n",
      "     disgust       1.00      0.09      0.17       107\n",
      "        fear       0.62      0.18      0.28      1015\n",
      "       happy       0.34      0.92      0.49      1824\n",
      "     neutral       0.44      0.26      0.33      1260\n",
      "         sad       0.48      0.19      0.28      1226\n",
      "    surprise       0.78      0.44      0.56       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.61      0.32      0.33      7178\n",
      "weighted avg       0.51      0.41      0.36      7178\n",
      "\n",
      "{'C': 1, 'degree': 3, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.11      0.14      1015\n",
      "       happy       0.43      0.67      0.52      1824\n",
      "     neutral       0.33      0.34      0.33      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 4, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.34\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.52      0.12      0.20       970\n",
      "     disgust       1.00      0.08      0.16       107\n",
      "        fear       0.59      0.15      0.23      1015\n",
      "       happy       0.29      0.94      0.44      1824\n",
      "     neutral       0.54      0.06      0.11      1260\n",
      "         sad       0.45      0.11      0.17      1226\n",
      "    surprise       0.81      0.29      0.42       776\n",
      "\n",
      "    accuracy                           0.34      7178\n",
      "   macro avg       0.60      0.25      0.25      7178\n",
      "weighted avg       0.50      0.34      0.27      7178\n",
      "\n",
      "{'C': 1, 'degree': 4, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.12      0.15      1015\n",
      "       happy       0.42      0.67      0.52      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 4, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.34\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.52      0.12      0.20       970\n",
      "     disgust       1.00      0.08      0.16       107\n",
      "        fear       0.59      0.14      0.23      1015\n",
      "       happy       0.29      0.94      0.44      1824\n",
      "     neutral       0.54      0.06      0.11      1260\n",
      "         sad       0.45      0.11      0.17      1226\n",
      "    surprise       0.81      0.29      0.42       776\n",
      "\n",
      "    accuracy                           0.34      7178\n",
      "   macro avg       0.60      0.25      0.25      7178\n",
      "weighted avg       0.50      0.34      0.27      7178\n",
      "\n",
      "{'C': 1, 'degree': 4, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.11      0.14      1015\n",
      "       happy       0.43      0.67      0.52      1824\n",
      "     neutral       0.33      0.34      0.33      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 5, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.32\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.86      0.07      0.13       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.80      0.10      0.17      1015\n",
      "       happy       0.27      1.00      0.43      1824\n",
      "     neutral       0.73      0.03      0.07      1260\n",
      "         sad       0.83      0.05      0.10      1226\n",
      "    surprise       0.95      0.21      0.34       776\n",
      "\n",
      "    accuracy                           0.32      7178\n",
      "   macro avg       0.78      0.22      0.20      7178\n",
      "weighted avg       0.69      0.32      0.22      7178\n",
      "\n",
      "{'C': 1, 'degree': 5, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.12      0.15      1015\n",
      "       happy       0.42      0.67      0.52      1824\n",
      "     neutral       0.34      0.34      0.34      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 1, 'degree': 5, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.25      0.31       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.43      0.26      0.32      1015\n",
      "       happy       0.53      0.76      0.62      1824\n",
      "     neutral       0.42      0.44      0.43      1260\n",
      "         sad       0.36      0.41      0.38      1226\n",
      "    surprise       0.71      0.57      0.63       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.55      0.39      0.40      7178\n",
      "weighted avg       0.48      0.47      0.46      7178\n",
      "\n",
      "{'C': 1, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.32\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.86      0.07      0.13       970\n",
      "     disgust       1.00      0.07      0.14       107\n",
      "        fear       0.80      0.10      0.17      1015\n",
      "       happy       0.27      1.00      0.43      1824\n",
      "     neutral       0.73      0.03      0.07      1260\n",
      "         sad       0.83      0.05      0.10      1226\n",
      "    surprise       0.95      0.21      0.34       776\n",
      "\n",
      "    accuracy                           0.32      7178\n",
      "   macro avg       0.78      0.22      0.20      7178\n",
      "weighted avg       0.69      0.32      0.22      7178\n",
      "\n",
      "{'C': 1, 'degree': 5, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.35\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.13      0.17       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.20      0.11      0.14      1015\n",
      "       happy       0.43      0.67      0.52      1824\n",
      "     neutral       0.33      0.34      0.33      1260\n",
      "         sad       0.28      0.27      0.28      1226\n",
      "    surprise       0.41      0.37      0.39       776\n",
      "\n",
      "    accuracy                           0.35      7178\n",
      "   macro avg       0.27      0.27      0.26      7178\n",
      "weighted avg       0.32      0.35      0.32      7178\n",
      "\n",
      "{'C': 10, 'degree': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.62      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.28      0.13      0.18       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.13      0.17      1015\n",
      "       happy       0.44      0.71      0.54      1824\n",
      "     neutral       0.35      0.36      0.35      1260\n",
      "         sad       0.30      0.33      0.31      1226\n",
      "    surprise       0.50      0.43      0.46       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.30      0.30      0.29      7178\n",
      "weighted avg       0.35      0.38      0.35      7178\n",
      "\n",
      "{'C': 10, 'degree': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.13      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.15      0.12      0.13      1015\n",
      "       happy       0.40      0.54      0.46      1824\n",
      "     neutral       0.27      0.26      0.26      1260\n",
      "         sad       0.23      0.20      0.21      1226\n",
      "    surprise       0.30      0.30      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.63      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.66       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.28      0.13      0.18       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.13      0.17      1015\n",
      "       happy       0.44      0.71      0.54      1824\n",
      "     neutral       0.35      0.36      0.35      1260\n",
      "         sad       0.30      0.33      0.32      1226\n",
      "    surprise       0.50      0.43      0.46       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.30      0.30      0.29      7178\n",
      "weighted avg       0.35      0.38      0.35      7178\n",
      "\n",
      "{'C': 10, 'degree': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.14      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.16      0.13      0.14      1015\n",
      "       happy       0.40      0.53      0.46      1824\n",
      "     neutral       0.26      0.25      0.26      1260\n",
      "         sad       0.23      0.21      0.22      1226\n",
      "    surprise       0.30      0.29      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.62      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.39\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.25      0.30      0.27       970\n",
      "     disgust       0.39      0.36      0.37       107\n",
      "        fear       0.28      0.30      0.29      1015\n",
      "       happy       0.51      0.54      0.52      1824\n",
      "     neutral       0.37      0.36      0.36      1260\n",
      "         sad       0.32      0.26      0.29      1226\n",
      "    surprise       0.59      0.52      0.55       776\n",
      "\n",
      "    accuracy                           0.39      7178\n",
      "   macro avg       0.39      0.38      0.38      7178\n",
      "weighted avg       0.39      0.39      0.39      7178\n",
      "\n",
      "{'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.13      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.15      0.12      0.13      1015\n",
      "       happy       0.40      0.54      0.46      1824\n",
      "     neutral       0.27      0.26      0.26      1260\n",
      "         sad       0.23      0.20      0.21      1226\n",
      "    surprise       0.30      0.30      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 2, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.63      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.66       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.39\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.25      0.30      0.27       970\n",
      "     disgust       0.39      0.36      0.37       107\n",
      "        fear       0.28      0.30      0.29      1015\n",
      "       happy       0.51      0.54      0.52      1824\n",
      "     neutral       0.37      0.36      0.36      1260\n",
      "         sad       0.32      0.26      0.29      1226\n",
      "    surprise       0.59      0.52      0.55       776\n",
      "\n",
      "    accuracy                           0.39      7178\n",
      "   macro avg       0.39      0.38      0.38      7178\n",
      "weighted avg       0.39      0.39      0.39      7178\n",
      "\n",
      "{'C': 10, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.14      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.16      0.13      0.14      1015\n",
      "       happy       0.40      0.53      0.46      1824\n",
      "     neutral       0.26      0.25      0.26      1260\n",
      "         sad       0.23      0.21      0.22      1226\n",
      "    surprise       0.30      0.29      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.62      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.27      0.34       970\n",
      "     disgust       0.67      0.34      0.45       107\n",
      "        fear       0.47      0.29      0.36      1015\n",
      "       happy       0.49      0.75      0.60      1824\n",
      "     neutral       0.42      0.46      0.44      1260\n",
      "         sad       0.41      0.36      0.39      1226\n",
      "    surprise       0.70      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.52      0.44      0.46      7178\n",
      "weighted avg       0.48      0.48      0.47      7178\n",
      "\n",
      "{'C': 10, 'degree': 3, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.13      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.15      0.12      0.13      1015\n",
      "       happy       0.40      0.54      0.46      1824\n",
      "     neutral       0.27      0.26      0.26      1260\n",
      "         sad       0.23      0.20      0.21      1226\n",
      "    surprise       0.30      0.30      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 3, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.63      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.66       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.27      0.34       970\n",
      "     disgust       0.67      0.34      0.45       107\n",
      "        fear       0.47      0.29      0.36      1015\n",
      "       happy       0.49      0.75      0.60      1824\n",
      "     neutral       0.41      0.46      0.44      1260\n",
      "         sad       0.41      0.36      0.39      1226\n",
      "    surprise       0.70      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.52      0.44      0.46      7178\n",
      "weighted avg       0.48      0.48      0.47      7178\n",
      "\n",
      "{'C': 10, 'degree': 3, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.14      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.16      0.13      0.14      1015\n",
      "       happy       0.40      0.53      0.46      1824\n",
      "     neutral       0.26      0.25      0.26      1260\n",
      "         sad       0.23      0.21      0.22      1226\n",
      "    surprise       0.30      0.29      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 4, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.62      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.43      0.25      0.31       970\n",
      "     disgust       0.76      0.30      0.43       107\n",
      "        fear       0.50      0.29      0.37      1015\n",
      "       happy       0.36      0.81      0.50      1824\n",
      "     neutral       0.50      0.22      0.31      1260\n",
      "         sad       0.43      0.23      0.30      1226\n",
      "    surprise       0.66      0.51      0.58       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.52      0.37      0.40      7178\n",
      "weighted avg       0.46      0.42      0.39      7178\n",
      "\n",
      "{'C': 10, 'degree': 4, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.13      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.15      0.12      0.13      1015\n",
      "       happy       0.40      0.54      0.46      1824\n",
      "     neutral       0.27      0.26      0.26      1260\n",
      "         sad       0.23      0.20      0.21      1226\n",
      "    surprise       0.30      0.30      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 4, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.63      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.66       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.43      0.25      0.31       970\n",
      "     disgust       0.76      0.30      0.43       107\n",
      "        fear       0.50      0.29      0.37      1015\n",
      "       happy       0.36      0.81      0.50      1824\n",
      "     neutral       0.50      0.22      0.31      1260\n",
      "         sad       0.43      0.23      0.30      1226\n",
      "    surprise       0.66      0.51      0.58       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.52      0.37      0.40      7178\n",
      "weighted avg       0.46      0.42      0.39      7178\n",
      "\n",
      "{'C': 10, 'degree': 4, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.14      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.16      0.13      0.14      1015\n",
      "       happy       0.40      0.53      0.46      1824\n",
      "     neutral       0.26      0.25      0.26      1260\n",
      "         sad       0.23      0.21      0.22      1226\n",
      "    surprise       0.30      0.29      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.62      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 5, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.75      0.13      0.22       970\n",
      "     disgust       0.96      0.23      0.38       107\n",
      "        fear       0.75      0.17      0.28      1015\n",
      "       happy       0.30      0.97      0.46      1824\n",
      "     neutral       0.51      0.12      0.19      1260\n",
      "         sad       0.65      0.12      0.20      1226\n",
      "    surprise       0.89      0.38      0.53       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.69      0.30      0.32      7178\n",
      "weighted avg       0.59      0.37      0.32      7178\n",
      "\n",
      "{'C': 10, 'degree': 5, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.13      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.15      0.12      0.13      1015\n",
      "       happy       0.40      0.54      0.46      1824\n",
      "     neutral       0.27      0.26      0.26      1260\n",
      "         sad       0.23      0.20      0.21      1226\n",
      "    surprise       0.30      0.30      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 10, 'degree': 5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.34      0.35      0.34       970\n",
      "     disgust       0.95      0.35      0.51       107\n",
      "        fear       0.38      0.38      0.38      1015\n",
      "       happy       0.59      0.67      0.63      1824\n",
      "     neutral       0.44      0.43      0.43      1260\n",
      "         sad       0.39      0.35      0.37      1226\n",
      "    surprise       0.70      0.61      0.66       776\n",
      "\n",
      "    accuracy                           0.48      7178\n",
      "   macro avg       0.54      0.45      0.47      7178\n",
      "weighted avg       0.48      0.48      0.48      7178\n",
      "\n",
      "{'C': 10, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.75      0.13      0.22       970\n",
      "     disgust       0.96      0.23      0.38       107\n",
      "        fear       0.75      0.17      0.28      1015\n",
      "       happy       0.30      0.97      0.46      1824\n",
      "     neutral       0.51      0.12      0.19      1260\n",
      "         sad       0.65      0.12      0.20      1226\n",
      "    surprise       0.89      0.38      0.53       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.69      0.30      0.32      7178\n",
      "weighted avg       0.59      0.37      0.32      7178\n",
      "\n",
      "{'C': 10, 'degree': 5, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.28\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.15      0.14      0.14       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.16      0.13      0.14      1015\n",
      "       happy       0.40      0.53      0.46      1824\n",
      "     neutral       0.26      0.25      0.26      1260\n",
      "         sad       0.23      0.21      0.22      1226\n",
      "    surprise       0.30      0.29      0.30       776\n",
      "\n",
      "    accuracy                           0.28      7178\n",
      "   macro avg       0.21      0.22      0.22      7178\n",
      "weighted avg       0.26      0.28      0.27      7178\n",
      "\n",
      "{'C': 100, 'degree': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.29      0.13      0.18       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.13      0.17      1015\n",
      "       happy       0.44      0.71      0.55      1824\n",
      "     neutral       0.35      0.36      0.35      1260\n",
      "         sad       0.30      0.33      0.32      1226\n",
      "    surprise       0.49      0.43      0.46       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.30      0.30      0.29      7178\n",
      "weighted avg       0.35      0.38      0.35      7178\n",
      "\n",
      "{'C': 100, 'degree': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.14      0.14       970\n",
      "     disgust       0.09      0.01      0.02       107\n",
      "        fear       0.16      0.14      0.15      1015\n",
      "       happy       0.38      0.49      0.43      1824\n",
      "     neutral       0.25      0.22      0.23      1260\n",
      "         sad       0.22      0.19      0.20      1226\n",
      "    surprise       0.29      0.29      0.29       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.22      0.21      0.21      7178\n",
      "weighted avg       0.25      0.27      0.26      7178\n",
      "\n",
      "{'C': 100, 'degree': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.29      0.13      0.18       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.25      0.13      0.17      1015\n",
      "       happy       0.44      0.71      0.55      1824\n",
      "     neutral       0.35      0.36      0.36      1260\n",
      "         sad       0.30      0.33      0.32      1226\n",
      "    surprise       0.49      0.43      0.46       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.30      0.30      0.29      7178\n",
      "weighted avg       0.35      0.38      0.35      7178\n",
      "\n",
      "{'C': 100, 'degree': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.15      0.15       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.14      0.12      0.12      1015\n",
      "       happy       0.38      0.48      0.43      1824\n",
      "     neutral       0.24      0.21      0.22      1260\n",
      "         sad       0.22      0.18      0.20      1226\n",
      "    surprise       0.29      0.30      0.29       776\n",
      "\n",
      "    accuracy                           0.26      7178\n",
      "   macro avg       0.20      0.21      0.20      7178\n",
      "weighted avg       0.25      0.26      0.25      7178\n",
      "\n",
      "{'C': 100, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.32      0.27       970\n",
      "     disgust       0.26      0.34      0.29       107\n",
      "        fear       0.27      0.32      0.29      1015\n",
      "       happy       0.50      0.47      0.48      1824\n",
      "     neutral       0.37      0.32      0.34      1260\n",
      "         sad       0.32      0.24      0.27      1226\n",
      "    surprise       0.56      0.55      0.55       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.36      0.36      0.36      7178\n",
      "weighted avg       0.38      0.37      0.37      7178\n",
      "\n",
      "{'C': 100, 'degree': 2, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.14      0.14       970\n",
      "     disgust       0.09      0.01      0.02       107\n",
      "        fear       0.16      0.14      0.15      1015\n",
      "       happy       0.38      0.49      0.43      1824\n",
      "     neutral       0.25      0.22      0.23      1260\n",
      "         sad       0.22      0.19      0.20      1226\n",
      "    surprise       0.29      0.29      0.29       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.22      0.21      0.21      7178\n",
      "weighted avg       0.25      0.27      0.26      7178\n",
      "\n",
      "{'C': 100, 'degree': 2, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.23      0.32      0.27       970\n",
      "     disgust       0.26      0.34      0.29       107\n",
      "        fear       0.27      0.32      0.29      1015\n",
      "       happy       0.50      0.47      0.48      1824\n",
      "     neutral       0.37      0.32      0.34      1260\n",
      "         sad       0.32      0.24      0.27      1226\n",
      "    surprise       0.56      0.55      0.55       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.36      0.36      0.36      7178\n",
      "weighted avg       0.38      0.37      0.37      7178\n",
      "\n",
      "{'C': 100, 'degree': 2, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.26\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.15      0.15       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.14      0.12      0.12      1015\n",
      "       happy       0.38      0.48      0.43      1824\n",
      "     neutral       0.24      0.21      0.22      1260\n",
      "         sad       0.22      0.18      0.20      1226\n",
      "    surprise       0.29      0.30      0.29       776\n",
      "\n",
      "    accuracy                           0.26      7178\n",
      "   macro avg       0.20      0.21      0.20      7178\n",
      "weighted avg       0.25      0.26      0.25      7178\n",
      "\n",
      "{'C': 100, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.38      0.29      0.33       970\n",
      "     disgust       0.53      0.37      0.44       107\n",
      "        fear       0.41      0.31      0.35      1015\n",
      "       happy       0.55      0.67      0.60      1824\n",
      "     neutral       0.38      0.48      0.43      1260\n",
      "         sad       0.38      0.33      0.35      1226\n",
      "    surprise       0.65      0.63      0.64       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.47      0.44      0.45      7178\n",
      "weighted avg       0.46      0.47      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 3, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.14      0.14       970\n",
      "     disgust       0.09      0.01      0.02       107\n",
      "        fear       0.16      0.14      0.15      1015\n",
      "       happy       0.38      0.49      0.43      1824\n",
      "     neutral       0.25      0.22      0.23      1260\n",
      "         sad       0.22      0.19      0.20      1226\n",
      "    surprise       0.29      0.29      0.29       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.22      0.21      0.21      7178\n",
      "weighted avg       0.25      0.27      0.26      7178\n",
      "\n",
      "{'C': 100, 'degree': 3, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.47\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.38      0.29      0.33       970\n",
      "     disgust       0.53      0.37      0.44       107\n",
      "        fear       0.41      0.31      0.35      1015\n",
      "       happy       0.55      0.67      0.60      1824\n",
      "     neutral       0.38      0.48      0.43      1260\n",
      "         sad       0.38      0.33      0.35      1226\n",
      "    surprise       0.65      0.63      0.64       776\n",
      "\n",
      "    accuracy                           0.47      7178\n",
      "   macro avg       0.47      0.44      0.45      7178\n",
      "weighted avg       0.46      0.47      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 3, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.26\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.15      0.15       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.14      0.12      0.12      1015\n",
      "       happy       0.38      0.48      0.43      1824\n",
      "     neutral       0.24      0.21      0.22      1260\n",
      "         sad       0.22      0.18      0.20      1226\n",
      "    surprise       0.29      0.30      0.29       776\n",
      "\n",
      "    accuracy                           0.26      7178\n",
      "   macro avg       0.20      0.21      0.20      7178\n",
      "weighted avg       0.25      0.26      0.25      7178\n",
      "\n",
      "{'C': 100, 'degree': 4, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.45\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.39      0.27      0.32       970\n",
      "     disgust       0.47      0.36      0.41       107\n",
      "        fear       0.48      0.32      0.38      1015\n",
      "       happy       0.44      0.73      0.55      1824\n",
      "     neutral       0.43      0.37      0.40      1260\n",
      "         sad       0.39      0.30      0.34      1226\n",
      "    surprise       0.64      0.56      0.60       776\n",
      "\n",
      "    accuracy                           0.45      7178\n",
      "   macro avg       0.46      0.42      0.43      7178\n",
      "weighted avg       0.45      0.45      0.44      7178\n",
      "\n",
      "{'C': 100, 'degree': 4, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.14      0.14       970\n",
      "     disgust       0.09      0.01      0.02       107\n",
      "        fear       0.16      0.14      0.15      1015\n",
      "       happy       0.38      0.49      0.43      1824\n",
      "     neutral       0.25      0.22      0.23      1260\n",
      "         sad       0.22      0.19      0.20      1226\n",
      "    surprise       0.29      0.29      0.29       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.22      0.21      0.21      7178\n",
      "weighted avg       0.25      0.27      0.26      7178\n",
      "\n",
      "{'C': 100, 'degree': 4, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.45\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.39      0.27      0.32       970\n",
      "     disgust       0.47      0.36      0.41       107\n",
      "        fear       0.48      0.32      0.38      1015\n",
      "       happy       0.44      0.73      0.55      1824\n",
      "     neutral       0.43      0.37      0.40      1260\n",
      "         sad       0.39      0.30      0.34      1226\n",
      "    surprise       0.64      0.56      0.60       776\n",
      "\n",
      "    accuracy                           0.45      7178\n",
      "   macro avg       0.46      0.42      0.43      7178\n",
      "weighted avg       0.45      0.45      0.44      7178\n",
      "\n",
      "{'C': 100, 'degree': 4, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.26\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.15      0.15       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.14      0.12      0.12      1015\n",
      "       happy       0.38      0.48      0.43      1824\n",
      "     neutral       0.24      0.21      0.22      1260\n",
      "         sad       0.22      0.18      0.20      1226\n",
      "    surprise       0.29      0.30      0.29       776\n",
      "\n",
      "    accuracy                           0.26      7178\n",
      "   macro avg       0.20      0.21      0.20      7178\n",
      "weighted avg       0.25      0.26      0.25      7178\n",
      "\n",
      "{'C': 100, 'degree': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 5, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.65      0.17      0.27       970\n",
      "     disgust       0.79      0.31      0.44       107\n",
      "        fear       0.68      0.21      0.32      1015\n",
      "       happy       0.35      0.90      0.51      1824\n",
      "     neutral       0.39      0.32      0.35      1260\n",
      "         sad       0.46      0.19      0.27      1226\n",
      "    surprise       0.84      0.45      0.59       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.59      0.36      0.39      7178\n",
      "weighted avg       0.52      0.42      0.39      7178\n",
      "\n",
      "{'C': 100, 'degree': 5, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.27\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.14      0.14       970\n",
      "     disgust       0.09      0.01      0.02       107\n",
      "        fear       0.16      0.14      0.15      1015\n",
      "       happy       0.38      0.49      0.43      1824\n",
      "     neutral       0.25      0.22      0.23      1260\n",
      "         sad       0.22      0.19      0.20      1226\n",
      "    surprise       0.29      0.29      0.29       776\n",
      "\n",
      "    accuracy                           0.27      7178\n",
      "   macro avg       0.22      0.21      0.21      7178\n",
      "weighted avg       0.25      0.27      0.26      7178\n",
      "\n",
      "{'C': 100, 'degree': 5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.46\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.31      0.35      0.33       970\n",
      "     disgust       0.82      0.34      0.48       107\n",
      "        fear       0.36      0.38      0.37      1015\n",
      "       happy       0.58      0.64      0.60      1824\n",
      "     neutral       0.42      0.40      0.41      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.61      0.65       776\n",
      "\n",
      "    accuracy                           0.46      7178\n",
      "   macro avg       0.50      0.43      0.45      7178\n",
      "weighted avg       0.46      0.46      0.46      7178\n",
      "\n",
      "{'C': 100, 'degree': 5, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.65      0.17      0.27       970\n",
      "     disgust       0.79      0.31      0.44       107\n",
      "        fear       0.68      0.21      0.32      1015\n",
      "       happy       0.35      0.90      0.51      1824\n",
      "     neutral       0.39      0.32      0.35      1260\n",
      "         sad       0.46      0.19      0.27      1226\n",
      "    surprise       0.84      0.45      0.59       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.59      0.36      0.39      7178\n",
      "weighted avg       0.52      0.42      0.39      7178\n",
      "\n",
      "{'C': 100, 'degree': 5, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "Accuracy: 0.26\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.14      0.15      0.15       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.14      0.12      0.12      1015\n",
      "       happy       0.38      0.48      0.43      1824\n",
      "     neutral       0.24      0.21      0.22      1260\n",
      "         sad       0.22      0.18      0.20      1226\n",
      "    surprise       0.29      0.30      0.29       776\n",
      "\n",
      "    accuracy                           0.26      7178\n",
      "   macro avg       0.20      0.21      0.20      7178\n",
      "weighted avg       0.25      0.26      0.25      7178\n",
      "\n",
      "\n",
      "Best Combination: {'C': 10, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "Best Accuracy: 0.48\n",
      "\n",
      "Total combinations: 120\n",
      "Best model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_svc(X_train, y_train, X_test, y_test, label_encoder):\n",
    "    param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Wider range for regularization\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],  \n",
    "    'degree': [1, 2, 3, 4, 5]  # Ignored for non-poly kernels\n",
    "}\n",
    "\n",
    "    best_combination = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    all_combinations = list(ParameterGrid(param_grid))\n",
    "    \n",
    "    all_combinations = list(ParameterGrid(param_grid))\n",
    "    for combination in all_combinations:\n",
    "        print(combination)\n",
    "        svc_model = SVC(**combination)\n",
    "        svc_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = svc_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_combination = combination\n",
    "            \n",
    " # Print the best combination\n",
    "    print(\"\\nBest Combination:\", best_combination)\n",
    "    print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
    "    print(\"\\nTotal combinations:\", len(all_combinations))\n",
    "\n",
    "    # Train the best model on the entire training set\n",
    "    best_model = SVC(**best_combination)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model\n",
    "    with open(\"svc_model_standardscaler_grisearch_pca_dump.pkl\", \"wb\") as f:\n",
    "        dump(best_model, f, protocol=5)\n",
    "    print(\"Best model saved successfully!\")\n",
    "\n",
    "    return best_model, best_combination\n",
    "\n",
    "best_model, best_combination = train_and_evaluate_svc(X_train, y_train, X_test, y_test, label_encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAt4klEQVR4nO3de5DXdfXH8cPFXfbKArsgsLELrBgQWFFZKqGgIKaJWpZNiZjd7KJdLK0UxMmm0tRsDBsdNWsqJTRNkxiEzGuWgqhISOsKLMbeYW/gwuf3R8P7x7J8zusjb1asno+ZZmLPvr/f9+d6+OA570+fJEkSAwDAzPoe6gkAAN46SAoAgICkAAAISAoAgICkAAAISAoAgICkAAAISAoAgICkAAAISAp4S1m5cqX16dPHVq5ceainckAWLFhgffr06fazyspKO++88w7NhPZjf3N8K3nllVesT58+dvvttx/qqfxPIim8yfr06ZPpf/+pN8VDbe992LdvXxsxYoTNnDnzP25/1tbW2oIFC2zVqlWHeir4H9P/UE/gf82dd97Z7c+/+MUvbNmyZT1+Pn78+DdzWv9VTjrpJDv33HMtSRKrrq62m266yaZPn24PPPCAzZ49+02fz7p166xv3zf296/a2lq78sorrbKy0t75znf2zsSA/SApvMk++clPdvvzk08+acuWLevx8321t7dbfn5+b07tv8a4ceO67c8zzjjDJk+ebNdff31qUujs7LScnJw3fPPOIjc396B/JtBb+Oejt6Djjz/e3vGOd9jf//53++AHP2j5+fn27W9/28z+/c8jCxYs6DFmf/9u3dzcbBdffLG97W1vs9zcXKuqqrIf/OAHtnv37m6/t2XLFnvppZfs9ddfl3P7zW9+Y1OmTLGioiIrLi62SZMm2Q033BDijY2N9o1vfMMmTZpkhYWFVlxcbLNnz7bVq1f3+KxNmzbZnDlzrKCgwIYOHWpf/epXbceOHRn20BszadIkKy0tterqajP7//9u8Zvf/Ma++93v2siRIy0/P9+2bdtmZmZPPfWUnXzyyTZw4EDLz8+3adOm2WOPPdbjcx999FF773vfawMGDLCxY8fazTffvN/vTzs2X/3qV62ystJyc3OtvLzczj33XKuvr7eVK1fae9/7XjMzmzdvXvjnsL3/jf1gz7G+vt5eeukla29vl/tz2bJldtxxx1lJSYkVFhbakUceGc5PM7OdO3faFVdcYVOmTLGBAwdaQUGBTZ061VasWNHjs5qbm+28886zgQMHWklJic2dO9eam5vlHNB7eFJ4i2poaLDZs2fbxz/+cfvkJz9pw4YNe0Pj29vbbdq0abZ582b73Oc+Z6NGjbLHH3/cLrvsMtuyZYtdf/314Xcvu+wyu+OOO6y6utoqKytTP3PZsmV2zjnn2IwZM+wHP/iBmZmtXbvWHnvsMbvooovMzOyf//yn3XvvvfbRj37URo8ebf/617/s5ptvtmnTptmLL75oI0aMMDOzjo4OmzFjhr366qv2la98xUaMGGF33nmnPfzww29sR2XQ1NRkTU1NVlVV1e3nV111leXk5Ng3vvEN27Fjh+Xk5NjDDz9ss2fPtilTptj8+fOtb9++dtttt9n06dPtL3/5i73vfe8zM7M1a9bYzJkzrayszBYsWGBdXV02f/78TMeptbXVpk6damvXrrXzzz/f3v3ud1t9fb3dd999tmnTJhs/frwtXLjQrrjiCvvsZz9rU6dONTOzY445xsysV+b405/+1K688kpbsWKFHX/88alzf+GFF+zUU0+1yZMn28KFCy03N9defvnlbglp27Ztdsstt9g555xjn/nMZ2z79u1266232qxZs+yvf/1r+OewJEns9NNPt0cffdQ+//nP2/jx4+2ee+6xuXPnyn2IXpTgkPriF7+Y7HsYpk2blphZsmjRoh6/b2bJ/Pnze/y8oqIimTt3bvjzVVddlRQUFCT/+Mc/uv3epZdemvTr1y959dVXw8/mzp2bmFlSXV3tzvWiiy5KiouLk66urtTf6ezsTHbt2tXtZ9XV1Ulubm6ycOHC8LPrr78+MbPkrrvuCj9ra2tLqqqqEjNLVqxY4c4ljZkln/70p5O6urpk69atyVNPPZXMmDEjMbPk2muvTZIkSVasWJGYWTJmzJikvb09jN29e3dyxBFHJLNmzUp2794dft7e3p6MHj06Oemkk8LP5syZkwwYMCCpqakJP3vxxReTfv369Tie+x6bK664IjGzZMmSJT3mv+d7n3766cTMkttuu61HvDfmOH/+/Ez7/brrrkvMLKmrq0v9na6urmTHjh3dftbU1JQMGzYsOf/888PP7r333sTMkh/+8Ifdxk6dOnW/2443B/989BaVm5tr8+bNO+Dxd999t02dOtUGDRpk9fX14X8nnnii7dq1yx555JHwu7fffrslSeI+JZiZlZSUWFtbmy1btsyd955/l9+1a5c1NDSEf2J45plnwu89+OCDNnz4cPvIRz4Sfpafn2+f/exnD3CL/9+tt95qZWVlNnToUDv66KPtscces6997Wt28cUXd/u9uXPnWl5eXvjzqlWrbP369faJT3zCGhoawj5ra2uzGTNm2COPPGK7d++2Xbt22dKlS23OnDk2atSoMH78+PE2a9YsOb/f/e53dtRRR9kZZ5zRI6ZKRXtrjgsWLLAkSdynBLN/nwNmZr///e97/DPkHv369bOcnBwzM9u9e7c1NjZaV1eXvec97+lxDvTv39++8IUvdBv75S9/2Z0Dehf/fPQWNXLkyHBhHYj169fbc889Z2VlZfuNb9269Q1/5oUXXmh33XWXzZ4920aOHGkzZ860s88+204++eTwO7t377YbbrjBbrrpJquurrZdu3aF2JAhQ8L/r6mpsaqqqh43wSOPPPINz2tfp59+un3pS1+yPn36WFFRkU2cONEKCgp6/N7o0aO7/Xn9+vVmZu4/X7S0tNiOHTuso6PDjjjiiB7xI4880h588EF3fhs2bLCzzjory6b08GbNMc3HPvYxu+WWW+yCCy6wSy+91GbMmGFnnnmmfeQjH+n2H+nvuOMOu/baa3v8t6q993lNTY0NHz7cCgsLe8wPhw5J4S1q77/BZrH3zdfs3zfnk046yb75zW/u9/fHjRv3huc0dOhQW7VqlS1dutT++Mc/2h//+Ee77bbb7Nxzz7U77rjDzMyuvvpqu/zyy+3888+3q666ygYPHmx9+/a1iy++OPVvlgdbeXm5nXjiifL39t3He+b3ox/9KLUMtLCwsFf+Y3hWh3qOeXl59sgjj9iKFSvsgQcesIceesh++9vf2vTp0+1Pf/qT9evXz375y1/aeeedZ3PmzLFLLrnEhg4dav369bPvf//7tmHDhl6ZFw4eksJ/mEGDBvWozti5c6dt2bKl28/Gjh1rra2tmW6Ob0ROTo6ddtppdtppp9nu3bvtwgsvtJtvvtkuv/xyq6qqssWLF9sJJ5xgt956a7dxzc3NVlpaGv5cUVFhzz//vCVJ0u1pYd26dQd1vm/E2LFjzcysuLjY3W9lZWWWl5cX/ta+tyzzHzt2rD3//PPu76T9M9KbNUdP3759bcaMGTZjxgz78Y9/bFdffbV95zvfsRUrVtiJJ55oixcvtjFjxtiSJUu6bcf8+fO7fU5FRYUtX77cWltbuz0tHMpzAJSk/scZO3Zst/8eYGb285//vMeTwtlnn21PPPGELV26tMdnNDc3W1dXV/hz1pLUhoaGbn/u27evTZ482cws/M20X79+liRJt9+7++67bfPmzd1+dsopp1htba0tXrw4/Ky9vd1+/vOfu3PoTVOmTLGxY8faNddcY62trT3idXV1ZvbvbZw1a5bde++99uqrr4b42rVr97u/93XWWWfZ6tWr7Z577ukR27Pv9vxz175/AeitOWYtSW1sbOzxsz1PLHufA3tvi9m/S2ifeOKJbuNOOeUU6+rqsp/97GfhZ7t27bIbb7zRnQN6F08K/2EuuOAC+/znP29nnXWWnXTSSbZ69WpbunRpt7+Fm5ldcskldt9999mpp55q5513nk2ZMsXa2tpszZo1tnjxYnvllVfCmKwlqRdccIE1Njba9OnTrby83GpqauzGG2+0d77znaED+9RTT7WFCxfavHnz7JhjjrE1a9bYr371KxszZky3z/rMZz5jP/3pT+3cc8+1v//97zZ8+HC7884799ugt3LlSjvhhBNs/vz5++3ROFj69u1rt9xyi82ePdsmTpxo8+bNs5EjR9rmzZttxYoVVlxcbPfff7+ZmV155ZX20EMP2dSpU+3CCy+0rq4uu/HGG23ixIn23HPPud9zySWX2OLFi+2jH/2onX/++TZlyhRrbGy0++67zxYtWmRHHXWUjR071kpKSmzRokVWVFRkBQUFdvTRR9vo0aN7ZY5ZS1IXLlxojzzyiH3oQx+yiooK27p1q910001WXl5uxx13nJn9+xxYsmSJnXHGGfahD33IqqurbdGiRTZhwoRuiey0006zY4891i699FJ75ZVXbMKECbZkyRJraWk5kMOHg+VQlj4hvSR14sSJ+/39Xbt2Jd/61reS0tLSJD8/P5k1a1by8ssv9yh7TJIk2b59e3LZZZclVVVVSU5OTlJaWpocc8wxyTXXXJPs3Lkz/F7WktTFixcnM2fOTIYOHZrk5OQko0aNSj73uc8lW7ZsCb/T2dmZfP3rX0+GDx+e5OXlJccee2zyxBNPJNOmTUumTZvW7fNqamqSD3/4w0l+fn5SWlqaXHTRRclDDz3UozTy/vvvTy3R3ZeZJV/84hfd39lTknr33XfvN/7ss88mZ555ZjJkyJAkNzc3qaioSM4+++xk+fLl3X7vz3/+czJlypQkJycnGTNmTLJo0aJQ2rm3/R2bhoaG5Etf+lIycuTIJCcnJykvL0/mzp2b1NfXh9/5/e9/n0yYMCHp379/jxLNgz3HrCWpy5cvT04//fRkxIgRSU5OTjJixIjknHPO6Vb6vHv37uTqq69OKioqktzc3ORd73pX8oc//CGZO3duUlFR0WM/fOpTn0qKi4uTgQMHJp/61KeSZ599lpLUQ6hPkuzzrA+8xXzzm9+0X//61/byyy+zZATQy/hvCnjLW7FihV1++eUkBOBNwJMCACDgSQEAEJAUAAABSQEAEJAUAABB5ua1vVcy3J+BAwemxnbu3OlPor8/DbWOi7eGvVpDKG3BuD28/w5/2GGHuWPVdnlv+VJjBwwYEBX35q62S72dzNvnapE/9dmqAsn7fFVTETO33jwXVFxtl4rv2w3/Rualrs29O+f3pdbCUvNWc/M69L1tNjO5RtPgwYNTY3u6ytPU19e78ddee82Ne82RnZ2d7tjbbrvNjZvxpAAA2AtJAQAQkBQAAAFJAQAQkBQAAAFJAQAQkBQAAEHmPoW01wPu4fUi7O+l6XtTNd6KV3McW8Pt1ZerOuk9b6BKE9MroI6HqsOO+Wy1XaovxRNbz+/NXc07pm5ejVVvtVPb7cXV8YrpU1DUd8fMO/a7vbja5uLiYjfe1taWGlP9Lvu+EGtfqtdg9OjRqbGD8Q5snhQAAAFJAQAQkBQAAAFJAQAQkBQAAAFJAQAQZC5JVUsWe2VvseWTMaWdqtQvphwvdt7e3NRYJebV295yx1k+2yvPVPtMlfOp8d7c1WfHLNUcs/S1md7n3vmgzvGYc0mV2iretR9bkhrz3Wpp+ZKSEjfe2NiYGlP7TJWceq8hMPPPJTXvLHhSAAAEJAUAQEBSAAAEJAUAQEBSAAAEJAUAQEBSAAAEmfsUYmq4VT2yqttVddZe/bmq4VbLPMd8ttpub5/F9inEfLeqs45Zglr1GaglpmP6FGJ5+zRmSe8s4719ro6XOk+9Pp/YZbdj+hxilsaO/Wx1PLz9onq6duzY4cbVst3ePlevKciCJwUAQEBSAAAEJAUAQEBSAAAEJAUAQEBSAAAEJAUAQJC5T6Gtrc2NDxo0KDWWn5/vjlW1zl4dtZlf265q6lW9sjdezUvFPTHvQ8gyvjf3mVcXr+q/Y3s/vLnH1r17+1T1V6h9GnO8Y3sJvLmpz4757tj+ipjjqfqTVK+BN3fvXpjls713NZjF3xsUnhQAAAFJAQAQkBQAAAFJAQAQkBQAAAFJAQAQkBQAAEHmPgVVX+69d0DV6w8YMMCNq3plr0Y8Ly/PHVtYWOjGvfXJY+razfxaaTVW7dOYNfRjj5dXhx07b3UeenrzHRXqXFA1+arPwRsfu0+971bnYcw7DdRnq30W896P2OurpKQkNebdC8308aitrXXj3j3rYLxPhCcFAEBAUgAABCQFAEBAUgAABCQFAEBAUgAABJlLUlVpZ8ySxV7Zp5kuH/PKFNUytmVlZW7cK6/csWOHO1aVh3nzVuWTqqxNHa+YslFVcud9t/rs2OWtvaWa1fHq7Ox0494+V9sVU0pr5l8DamlsVbrpjY+59tR3xy7LHbNd6jxSS2t7xzt2GXV1njY3N6fGtm7d6o7NgicFAEBAUgAABCQFAEBAUgAABCQFAEBAUgAABCQFAECQuU9Biam5V3XvqmbYqx8fMmSIO9ZbAtesd+vDvVpn1YegarhVzb03N7VdKu5RxzK2Nr2joyM1tn37dndszLLD6hwuLi5246qvxDsfYvaJmX99qmOtrm3veKpeAfXZMXOLOYfN/F4C1afQ3t7uxtV52tDQkBr7xz/+4Y7NgicFAEBAUgAABCQFAEBAUgAABCQFAEBAUgAABCQFAECQuU/BW3/fzK+zzs/Pd8eqOmtVA+69EyH2XQ1e7braJzF11mpNdUXNzft89W6AmF4CVcOtegVi+hxi39XgfbbqC1H7VPWlePGYXgEz/zyMXfvfm3dsf5LqNVDnmkcdT29uqg/hX//6lxtvbGx04947E3ifAgDgoCIpAAACkgIAICApAAACkgIAICApAACCg7Z0tleipUr9VGmaKq/0liVWpYAxcVXypkoBY0ocVRmvKiX09qkqM4xZtttbYl3Ny0yXbnqfr0oc1T73SiBV6XNbW5sbV9fAgAEDDmheWcSMjynjVeeZOscVr7xZlT6r4+WdK2rp69dee82NNzc3u/EtW7akxtQ5ngVPCgCAgKQAAAhICgCAgKQAAAhICgCAgKQAAAhICgCAIHOfQkzNvbestpmuPVdLb3s13qoeWfE+W/U4qO+OqaNWx0Mt39vS0nLA363qy706646ODndsbJ+Ct4z60KFD3bGqT2Hbtm2pMbW/i4qK3LjqFVD7zaOuH6+nRdW9q14dr29E9dKo3o2YpbdVD4Q6Ht7xVktfq6WzvfNMjVf7JAueFAAAAUkBABCQFAAAAUkBABCQFAAAAUkBABCQFAAAQeY+hZh1ulU9soqr2nSvVjq2btfrB4jtr/DWold9CKpuXa0H7/UpqPXcVU3+kCFDUmPeuy/MdH24qotfv359amz16tXu2FGjRrlx750Gal7qvQNquwcPHpwai92n3rmmjrW6L3jXiHq3Rmyvjnftq32i5uaNb2hocMe2tra6cfU+Bu9cKywsdMdmwZMCACAgKQAAApICACAgKQAAApICACAgKQAAgswlqaq0s6CgIDWmSsdU6VnM8r2xJalqiV2PWgbai6t9psrWVMmqt11qn6lSXK9czyuFNdPnglpW2DtXVJnhc88958aHDRuWGvPKcM30uaDKsr39oq4PdS5549Uy6SruzTvm2jLzS4TN/FJdtb9j9mlTU5M7Vp3DdXV1B/zd6trMgicFAEBAUgAABCQFAEBAUgAABCQFAEBAUgAABCQFAECQuag1Ly/PjXs1w6oeWdUMq2VuvWWJ1XeremSv/+Kwww5zx6plbL2ltb2lks3MRowY4cbVdnnxzs5Od+zmzZvduFcfrvortmzZ4sbXrVvnxpcuXZoa846lmdn73vc+N+4pKytz46r/QtXcez0WqjZdfba3zLpaRl3V3HufrfZJ7PXl9VCo+5mam3c81Dm+detWN15fX+/G1X6JxZMCACAgKQAAApICACAgKQAAApICACAgKQAAApICACDI3Keg1qL3+gFUzbxav1/1Gnh1u967FtRYRfVXKF7/Rcz7K8zi3sfw2muvuWMPP/xwN+7tUzV24sSJbvyDH/ygG583b15q7PHHH3fHrl692o17vSOVlZXuWNUroPocvJp8r9/FTF8/Xp+P6htRNfWq3t/j9buY6T4Fj7fNZvr68+4r6h0Tap+2t7e7ce94x+zvPXhSAAAEJAUAQEBSAAAEJAUAQEBSAAAEJAUAQEBSAAAEmfsUcnNz3bhXC61qZ1UdtXqfgje32Hrk3twur/dDzVtRfSXeevLqXQ4tLS1uvLW19YDHqnr+mL6TOXPmuGNPOeUUN+71hqi+EaWoqMiNe+eD6rXx3mlg5l9fau3/xsZGN656KDyx71vwvlsdL3XP8XoJVF+W2mcx74BR350FTwoAgICkAAAISAoAgICkAAAISAoAgICkAAAIMpekxpRfxizdm4VaJtqj5uZ9tiqPVOVhXkmd2ieq5FSVEHvleqqMMKZkVZXjeeWsWXjHa9u2be5Ytay3t1SzOl7qeHglwmb+Mu3qu2PKFFWJsFq+2jue6tpTVq1a5cbHjBmTGhsxYoQ7Vm2Xt8/VvbKjo8ONq+vP+3xKUgEABxVJAQAQkBQAAAFJAQAQkBQAAAFJAQAQkBQAAEHmPgXFqzlWtbOqRrt/f3+aXlz1MOzYscONe/XhXsxM1yt7y/OqsapPQS3968XVdqk6ai8+bNgwd6zabnU8vfpxtV2Kt8/UOa7O4Zi5qX2izhVv2e6jjjrKHXv//fe78bKystSYuu5VH4PqK6mpqUmNbdy40R1bWVnpxr0l97dv3+6OVb04MT0vqhcnC54UAAABSQEAEJAUAAABSQEAEJAUAAABSQEAEJAUAABB5j6FmLp3VSetarRj3regap1VXbxXf+69D8FM14/HvIMi5h0SitouNTfvXFDHMnafenH13eqzvdr0mF6aLN/txdVY1UPhXZ8FBQXu2BNPPPGAv1vN+8orr3TjDQ0Nbtybm3q/RXt7uxv3eiReeOEFd6x6R4WaW2dnpxuPxZMCACAgKQAAApICACAgKQAAApICACAgKQAAgjelJFWVMMaUnJr1bnmmV7L6+uuvH/BYFVelmYra597cVQmxintzjy0RjinzVWPVPvfKSmOOtVnc3GKOh5lZYWFhakyVs6rlq73STlWK/r3vfc+Nr1y50o1XV1enxlRZqFpS/5lnnkmNNTY2umO90mYzfTxjrt0seFIAAAQkBQBAQFIAAAQkBQBAQFIAAAQkBQBAQFIAAASZ+xRUL4FXhx1bw63qemP6HFR9uDc3VcOtlrj16t7VUsuxy0B74zs6OtyxeXl5btyrAVfHWvV+qO329puqi1e9ONu2bUuNqXmr+vGY463GxigpKYka7+2z+vp6d6xatvvMM8904y+99FJq7Nlnn3XHqvOsqakpNaauH/XZqkfCux+q6ysLnhQAAAFJAQAQkBQAAAFJAQAQkBQAAAFJAQAQkBQAAEHmAmdV9+7FY8aa6dpbrwZc1YfHvItB9SmounhvnXtVe67mHVPvn5ub645VddRevX/sewVUjbe33aoPQfWVHIwa8DTqeMec4+odFl68tbXVHVtWVubGjz766NTYK6+84o6tqalx45s2bXLj3vU5atQod6z3jgkzs+bm5tSY15thpns/VJ9D7LtWFJ4UAAABSQEAEJAUAAABSQEAEJAUAAABSQEAEJAUAADBQetT8GqdVX24qqOOqblXvQIxfQpqXmq7vHmream69pj1+WP7L7x4zLsvzOLeYaHGFhUVufH8/PzUmOrtUPX+Ku69w0LNW9W1e3Xxamx7e7sb9+ZdXl7ujh06dKgbV+9jqK2tTY2pe1Jpaakb/+tf/+rGPeq+EXO/VJ+dBU8KAICApAAACEgKAICApAAACEgKAICApAAACDKXpCpeKZRaknjAgAFuPKasNLb8y/tuNfZglIeliS1J9UoN1bxjlrdWY9Wy3Opc8o6JOo/q6urc+MCBA1NjgwYNcseq0s2WlhY37i3VPGTIEHdsTk6OG/f2mfe9ZmbFxcVu3DueXomvmb4vqJJWb79s3brVHavOQ6+8Ofa+oI6Xdw3Elnyb8aQAANgLSQEAEJAUAAABSQEAEJAUAAABSQEAEJAUAADBm7J0tqrLVbXnqm43pmZYfXZM/4WqGfbmpuqk1bxjej9UPb86nmqJas+2bdvcuFqOfNy4camxxsZGd+yjjz7qxr3jqY6HWua5b1//72djx45NjY0aNcodq86Ftra21FjMcuJmcTX1at7qPIzpE1LXnzqXPGo5crVfvOsz5lUAe/CkAAAISAoAgICkAAAISAoAgICkAAAISAoAgICkAAAIMvcpqJpfr7ZW1ZarXgJV9+69O0DNu6ury41741Uts+Jtt6plVnXxubm5btyrdVbf3dHR4ca9fabW51fbpWryvblVVla6Y5VVq1alxjZu3OiO3bx5sxtXx6ugoCA1pt4N0Nra6sa9XoJJkya5Y8vKyty4d+3GvhNE9Ql517a6J6l7zvbt2924R93v1D3Jm7vqMcqCJwUAQEBSAAAEJAUAQEBSAAAEJAUAQEBSAAAEB60k1SsfUyVWqvxLlUh6JVpqSeKY0jRVkqpKz7zxsSWpKu6VEKt5q1LBLVu2pMbU0r6qBFItp1xYWJgaU/N+97vf7canTJmSGmtvb3fH/uUvf3Hjatlur+xUnYeqXNY7JqoEWN0XvKXQ1X1BxRXvPFafrY5nU1PTAc3JLL4k1bunqWW3s+BJAQAQkBQAAAFJAQAQkBQAAAFJAQAQkBQAAAFJAQAQZO5TULxaZ9ULoOqsVe1tfn5+akzVpqs+Bu+71bxi6pFV/XdsrbM3d9VLUFtb68a9fTpx4kR3rNdnYGY2aNAgN+6dC6rHIWbZ4ZKSEjd+wgknuHF1jbzwwgupMbVP3v/+97vxtra21Njb3/52d6w6VxoaGlJjqj9J7ZO8vDw37i1vre45aon3+vr61Ji6L6hrW92TvPOUPgUAwEFFUgAABCQFAEBAUgAABCQFAEBAUgAABCQFAECQuU9B1cXHUHW7qn7cGx/7PgVPTI+Dma7xjhmr9qlHrSWv6v3Hjx+fGisoKHDHqr6Szs5ON56bm5saU+dwR0eHG/fOFXWOqu2ePn26G//ABz6QGlPvzlDb5dXzq34XdTy8en91jqrv9npSzPxeBPXd6h0U3napc1idh+q+4l379CkAAA4qkgIAICApAAACkgIAICApAAACkgIAICApAACCzH0KMWuAq7rc2PcSeHOL7RXwxqt6YlWv7NW9x74HIiauxo4ePdqNe8erpaXFHVtXV+fGVU2+9/lqjXyvXl/FVR9CUVGRG1fvmaiqqkqNqR6Jww47zI1777DYunWrO1YdT+99Cqp/Qr3zQPUpeO9bUP0VGzZscOPefUO9E0T1Aan7nRdX124WPCkAAAKSAgAgICkAAAKSAgAgICkAAAKSAgAgyFySqpax9creVMmcKguNKdFS844p3VTlrmq7vc9WJanqs1XpplfOV1xc7I7dtm2bG/dKDVWJoyoFVMertbU1NRa73HhMGWJtba0bX758uRv3Sl5LS0vdsd6y22Zm73nPe1Jjapl0tV1NTU2pMbW/1fWllr33Sj+9eZmZrVu3zo17149XCpuFKpf1zkN1v8uCJwUAQEBSAAAEJAUAQEBSAAAEJAUAQEBSAAAEJAUAQJC5TyGml0DVlqs+BDXeq3eO7ZGIEbNstxqrlkNWSzl7vQiqD0HVeD/88MOpsRdeeMEdq5avPvLII924t5RzRUWFO7asrMyNT5o0KTVWXl7ujn3++efdeFtbmxuvqalJjT311FPu2BdffNGNe8uVT5061R2rrl3Pzp073bg6D9U14PUpVFdXu2NVPDc3NzWm7jmqjyFmSX7V45AFTwoAgICkAAAISAoAgICkAAAISAoAgICkAAAISAoAgCBzn4Ja+9yr21Xrnqu4qkf25qbG7tixw4177yVQ7yxQ3x3T26G+W62D78XVZ69cufKA4+pdDSqu1u/3zoWGhgZ3rFqL3hs/YcKEA56Xmdm0adPc+Jo1a1Jjqtdm8+bNbtzrKxk8eLA7tqSkxI1717bqU1Cam5vduNfzsnbt2gMea+a/T0Fdu+q+oMZ7+1T1SGTBkwIAICApAAACkgIAICApAAACkgIAICApAACCzCWpaolcb5laVWYYU3Jq5i8lq8pdY8q/VAmj+mxveWy1T7xtNtOlad7c1LLbxx13nBt/6KGHUmPqeKgSRyVmWWEVf+aZZ1Jjjz/+uDtWlQg/8MADbtxTWlrqxlUZb2FhYWps1apV7tjKyko37p3H6p6i4t4y6Wb+Eu+qJFWdpzFiP9s7l9Q9JwueFAAAAUkBABCQFAAAAUkBABCQFAAAAUkBABCQFAAAQeY+BbXMrVcXH7M8tVlc7a36bsXrJYitCfZquFUfgjevLLy5qzrqyZMnu/GTTz45Nfbggw+6Y/Py8ty42i/eMtJqrFevb2ZWVFTkxj2qB2LLli1u3DteapnnESNGuHGvH0D1CqieFq+mXu0Tdc9R18CGDRtSY5s2bXLHeq8CMPPvd2qfqaXO1XZ5c6NPAQBwUJEUAAABSQEAEJAUAAABSQEAEJAUAAABSQEAEGTuU1Dr83u1t967Fszi3w3gfXfs2uXeeFVvHFMzrGqV1fsWVO+Ht09VPb6qw547d25qrK2tzR3rrYFvZlZVVeXGvbmtX7/eHdvR0eHGvX2uzgV1Dg8fPtyNNzc3p8Zi30FxxBFHpMYmTpzojlU9EN7xVueROsc3btzoxtesWePGY747prdDUeeKisfiSQEAEJAUAAABSQEAEJAUAAABSQEAEJAUAABB5pLU1tZWNz5w4MDUmCrR6urqcuOqBMsrG1VloTHL86qyURX3tkuVxBUXF7txtQy0Nzd1vNR2ecslX3TRRe7YlStXunFValtWVpYaGzx4sDu2rq7OjXvllWqJdnUO19bWunGvrLulpcUd6y1lbmY2c+ZMN+5Ry1/HLF2vzsOnn37ajTc2NqbGvPuVWXwpe2/y9osqjc6CJwUAQEBSAAAEJAUAQEBSAAAEJAUAQEBSAAAEJAUAQJC5T0EtO/yud70rNaZq7r1lgc300sC5ubmpsddff90dG7NMbexnezX3ajlx1aeQn5/vxrdv354aU/XhqlfA62NQfSOnnnqqG1+1apUb37ZtW2ps0qRJ7ljVs+J9ttpnBQUFbvxvf/ubG3/qqadSY6oPYfbs2W7cWyq9urraHav2mXdtql6AJ5980o3/85//dOPeNaCuL9V/4V3b6lyIXRrb+3zVQ5QFTwoAgICkAAAISAoAgICkAAAISAoAgICkAAAISAoAgCBzn8LGjRvd+PDhw1Njo0aNcseqen9vHXszv65X1e2qmmKvrl7NW9Xze2ufx77TIKaXQL3fwlvbX41X73lQn616Dbz1+9V7B1TNvbcGf1NTkzv28MMPd+OK11cya9Ysd6zq8/HONTU25n0lL730kjv22WefdeOql8A7x1WPhNou79rt6Ohwx3rvGzGL62NQY7PgSQEAEJAUAAABSQEAEJAUAAABSQEAEJAUAAABSQEAEGTuU1A13N469159t5lZXl6eG29sbHTjXl28qrP26o3N/LpfNVbFvfpwr97eTPcSqDprb517Vf+t3o/hvXdA9SEo6jwsLS1NjanzUG23intU7brq35g2bVpqTPWkqHhM3XtDQ4MbX7t2bWps8eLF7tjW1lY3ru4b3jWi3jei9pl3Hns9JWa6B0n1P3nXn7rnZMGTAgAgICkAAAKSAgAgICkAAAKSAgAgICkAAILMJamqDLG5uTk1ppbAnTx5shtXZXFeyaoaq0rTvCV2VYljTGmZKltTSzUXFxe78UGDBqXGVAmwKpf1SgXr6urcsWpJY1Xu583dK8PN8t1euZ8qEVbLv6vyS29uXhmumVn//v5l7i3lrI71k08+6cYffPDB1Jg6lup4qWskZqw6nl7JqrqnqGtXlZN7cUpSAQAHFUkBABCQFAAAAUkBABCQFAAAAUkBABCQFAAAQeY+BVXX69U619bWumNVTfC4cePcuNeLsHHjRnfs4Ycf7sYHDx6cGlN11kVFRW7c22611HJMvb6ZX+usehxU/4Wam8frdzHTS2972xW7xLTq1fGo2nNVX+71Gqh6ftWr441fsmSJO/aBBx5w415/hVouXJ1nqv/Cu2fF9DiY+fc71b+kjkefPn3c+MHoRfDwpAAACEgKAICApAAACEgKAICApAAACEgKAICApAAACDL3KajaWfdLRD3xa6+95sZVbfrIkSNTY6qGu6amxo3v3LnzgL7XTO8z77MV9dlquz3Dhg1z46q+PGZ9ftWfUV9f78a99xKounc1N9XH4FHXgDpeb3vb21Jj6n0Kqm7+uuuuS4394Q9/cMd6x9rM7+1Q75BQ55l6R4V3vNT1o/oY1LnkUf0u6ru9uaseiCx4UgAABCQFAEBAUgAABCQFAEBAUgAABCQFAEDQJ8m4DmteXp4b95aBViVYagqqRMubmyojVEsae+MrKircsZMnT3bj3hLVap+pkjpVmjZmzJjUWHl5uTtWLTfulUCqeasyxU2bNrnxV199NTWmllFXpc+dnZ0HFDPTpZve8TAz+8AHPpAaU+f4jTfe6Mb/9Kc/pcbUda9KM2OWG1f7VJX5evckdX2o5fy9uBrrLSduFndtq33iXR978KQAAAhICgCAgKQAAAhICgCAgKQAAAhICgCAgKQAAAgy9ymoOmuv3l/V5apeAVX36/UxqDppVa/sfbbqn1C158cee2xqTPUCqCWm1WH1jmdVVZU7VvVneHMfNGiQO7agoMCNK95y5C0tLe7YpqYmN+4trR27DPTw4cPduPf5P/nJT9yxy5cvd+NeX4m69mKoPgRF9Wd454JaJl3dkzLeNg/os9U9KeY1BtXV1fJ3eFIAAAQkBQBAQFIAAAQkBQBAQFIAAAQkBQBAQFIAAAT+4tsHSUxdbRa5ubmpMdVfoerLvXpkVau8YcMGN759+/bU2Pvf/353rOoVUNvl9TmsW7fOHavqy70acNWzourHvWNt5teAFxUVuWNLSkrcuFf3rvpGVJ9Cc3OzG//hD3+YGnviiSfcsV4fgpnfi6COl+rV8eLqWKoeibq6ugMer75bvUdC9Rp4evN+GNM/sQdPCgCAgKQAAAhICgCAgKQAAAhICgCAgKQAAAhICgCAIPP7FNTa5TFUTbDqNfDq5tva2tyxavO9Ou3+/f02D/XZXly9V2DChAlufNy4cW7c6wdQ67mruZWWlqbGVH/FsGHD3PiQIUPcuFd/ruat6vm9mnt1DtfW1rpxrw/BzOzpp59Ojal3hsS8t0Cdw+pc8a4fdW2quNou77tVz4o6F7ztVr0dap8pMe+u4X0KAIA3hKQAAAhICgCAgKQAAAhICgCAgKQAAAgyl6SqkruYUkC1RK4qTfOWNFYlWvn5+W7cK0NUyzyrXevtUzVvb5vNzMrLy924V7KqlvZVc/O2S5WUqnNFLW/txSsrK92xgwcPduNeWfbWrVvdsbfffrsbf+6559y4d32p5avVeeiVVqvzTGlpaUmNNTU1uWPV8tQq7m23KuNV56ka35u8ktbY5fzNeFIAAOyFpAAACEgKAICApAAACEgKAICApAAACEgKAIAgc58CAOC/H08KAICApAAACEgKAICApAAACEgKAICApAAACEgKAICApAAACEgKAIDg/wCBh9PbO2YEXAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuG0lEQVR4nO3de5CW5X3/8c+CsLAn2AOH5Yygckq1gsmEVHFSaKVUmo6JY/EAyZhq0Ga0rUlMO9W0TaxpGhNtNWmbQRs1rahxbBIjGJNGbU0PKhJRAeUssMCyy8JySNn790eHa1iW5/t54GIlv+T9mulM3e9e93OfnuebZ/lc111RFEUhAAAk9TndOwAA+PlBUwAAJDQFAEBCUwAAJDQFAEBCUwAAJDQFAEBCUwAAJDQFAEBCUwBOg4qKCt1+++3pv++//35VVFRo/fr1p22fjnXsPv68WbRokcaNG3e6d+MXDk3hFKqoqCjr/370ox+d7l39pXb77bd3ux5VVVWaMmWK/vRP/1R79uw53bt3Qh5++GF95StfOd27gV8gZ5zuHfhF8s1vfrPbf//TP/2Tli9f3uPnkydPfjd3CyXcd999qqmp0d69e7Vs2TJ9/vOf17PPPqsXXnhBFRUV7+q+XH311briiitUWVl5QuMefvhh/fSnP9VNN93UOzuGXzo0hVPoqquu6vbfL774opYvX97j58fq7OxUVVVVb+7a/3e6urp06NAhDRgwoNde48Mf/rCampokSddff70uu+wyPf7443rxxRf1/ve//7hjeuta9e3bV3379j3l2wVOFH8+epddfPHFmjZtmv7nf/5HF110kaqqqvTZz35WUum/4Y4bN06LFi3q9rO2tjbddNNNGj16tCorKzVx4kTdeeed6urq6vZ7W7du1RtvvKGf/exndt++9KUvaebMmWpsbNTAgQM1ffp0Pfrooz1+r6KiQjfeeKOeeOIJTZs2TZWVlZo6daq+//3v9/jdH/3oR5oxY4YGDBigCRMm6Otf/3r6883xtvnQQw9p6tSpqqys1FNPPaVx48bpd37nd3ps98CBAxo0aJCuu+46e1zl+uAHPyhJWrdunaT4Wh08eFC33XabJk6cqMrKSo0ePVqf+tSndPDgwW7bPHjwoG6++WYNGTJEtbW1mj9/vjZv3tzjtUv9m8JTTz2lWbNmqba2VnV1dbrgggv08MMPp/377ne/qw0bNqQ/hR39N/ZTvY+S9MYbb2jjxo32XHZ0dOimm27SuHHjVFlZqaFDh2rOnDl66aWX0u8899xz+shHPqIxY8ak/bv55pu1f//+Hts7cq8NGDBA06ZN07e//W27Dzg5fFM4DXbt2qW5c+fqiiuu0FVXXaVhw4ad0PjOzk7NmjVLW7Zs0XXXXacxY8bo3//933Xrrbdq69at3f7GfOutt+qBBx7QunXr7D/KffWrX9X8+fN15ZVX6tChQ/rnf/5nfeQjH9F3vvMdzZs3r9vvPv/883r88ce1ePFi1dbW6u6779Zll12mjRs3qrGxUZL08ssv65JLLlFzc7M+97nP6fDhw/rzP/9zDRky5Liv/+yzz+qRRx7RjTfeqKamJo0fP15XXXWVvvjFL6q1tVUNDQ3pd//1X/9Ve/bssd/CTsRbb70lSWn/peNfq66uLs2fP1/PP/+8fv/3f1+TJ0/WypUrddddd2n16tV64okn0vhrr71WDz74oBYsWKCZM2fq2Wef7XEuS7n//vv1sY99TFOnTtWtt96qwYMH6+WXX9b3v/99LViwQH/yJ3+i9vZ2bd68WXfddZckqaamRpJ6bR8nT56sWbNm2X8Xu/766/Xoo4/qxhtv1JQpU7Rr1y49//zzev3113X++edLkpYuXarOzk594hOfUGNjo/7zP/9T99xzjzZv3qylS5embS1btkyXXXaZpkyZojvuuEO7du3SRz/6UY0aNaqs84gTVKDX3HDDDcWxp3jWrFmFpOJrX/taj9+XVNx22209fj527Nhi4cKF6b//4i/+oqiuri5Wr17d7fc+85nPFH379i02btyYfrZw4cJCUrFu3Tq7v52dnd3++9ChQ8W0adOKD37wgz32s3///sXatWvTz1asWFFIKu655570s0svvbSoqqoqtmzZkn62Zs2a4owzzuhxXiQVffr0KV577bVuP3/zzTcLScV9993X7efz588vxo0bV3R1ddnjOtZtt91WSCrefPPNYseOHcW6deuKr3/960VlZWUxbNiwYt++fUVRlL5W3/zmN4s+ffoUzz33XLeff+1rXyskFS+88EJRFEXxyiuvFJKKxYsXd/u9BQsW9LjWS5Ys6Xad2traitra2uJ973tfsX///m7jjz7mefPmFWPHju1xjL2xj0Xxf9dp1qxZPV7vWIMGDSpuuOGG8HeOvd+KoijuuOOOoqKiotiwYUP62XnnnVc0NzcXbW1t6WfLli0rJB332JGHPx+dBpWVlfroRz960uOXLl2qCy+8UPX19dq5c2f6v9mzZ+vw4cP68Y9/nH73/vvvV1EUZUX3Bg4cmP7/3bt3q729XRdeeGG3r/xHzJ49WxMmTEj//Su/8iuqq6vT22+/LUk6fPiwnnnmGX3oQx/SiBEj0u9NnDhRc+fOPe7rz5o1S1OmTOn2s7PPPlvve9/79NBDD6Wftba26qmnntKVV16Z9Q/C55xzjoYMGaLx48fruuuu08SJE/Xd7363278ZHO9aLV26VJMnT9akSZO6nf8jf3764Q9/KEn63ve+J0n65Cc/2W18Of8ovHz5cnV0dOgzn/lMj39XKeeYe2sfi6IoKz03ePBg/eQnP9E777xT8neOvt/27dunnTt3aubMmSqKQi+//LKk//vz5yuvvKKFCxdq0KBB6ffnzJnT417BqcGfj06DkSNHqn///ic9fs2aNXr11VdL/hmmpaXlpLb7ne98R3/5l3+pV155pdvfnY/3ITRmzJgeP6uvr9fu3bvTPuzfv18TJ07s8XvH+5kkjR8//rg/v+aaa3TjjTdqw4YNGjt2rJYuXaqf/exnuvrqq8s6rlIee+wx1dXVqV+/fho1alS3JnfE8a7VmjVr9Prrr9vzv2HDBvXp06fHds855xy7b0f+lDVt2rSyjuVY78Y+Rr74xS9q4cKFGj16tKZPn67f+q3f0jXXXKMzzzwz/c7GjRv1Z3/2Z3ryySfTfXNEe3t72j9JOuuss3q8xjnnnHPc/8GCPDSF0+Do/4VUjsOHD3f7766uLs2ZM0ef+tSnjvv7Z5999gnv03PPPaf58+froosu0r333qvm5mb169dPS5YsSf+webRSSZki4+mupc7LFVdcoZtvvlkPPfSQPvvZz+rBBx/UjBkzsj+4LrroopQ+OpF96urq0nve8x59+ctfPu6Y0aNHZ+3XqXC69/Hyyy/XhRdeqG9/+9tatmyZ/vqv/1p33nmnHn/8cc2dO1eHDx/WnDlz1Nraqk9/+tOaNGmSqqurtWXLFi1atKhHYALvHprCz5H6+nq1tbV1+9mhQ4e0devWbj+bMGGC9u7dq9mzZ5+y137sscc0YMAAPf30092y8kuWLDmp7Q0dOlQDBgzQ2rVre9SO97NIQ0OD5s2bp4ceekhXXnmlXnjhhdM6YWvChAlasWKFfv3Xfz38U87YsWPV1dWlt956q1sDe/PNN8t6DUn66U9/WvKblVT6T0nvxj46zc3NWrx4sRYvXqyWlhadf/75+vznP6+5c+dq5cqVWr16tR544AFdc801aczy5ct77J/0f998jnUq9hE98W8KP0cmTJjQ7d8DJOnv//7ve3xTuPzyy/Uf//Efevrpp3tso62tTf/7v/+b/rvcSGrfvn1VUVHR7bXWr1/fLaVyIvr27avZs2friSee6PZ35bVr1+qpp5464e1dffXVWrVqlW655Rb17dtXV1xxxUnt16lw+eWXa8uWLfqHf/iHHrX9+/dr3759kpT+7eTuu+/u9jvlNLTf+I3fUG1tre644w4dOHCgW+3ob2PV1dXpTy3vxj6WE0k9fPhwj30aOnSoRowYkf4seeSb5tHHUhSFvvrVr3Yb19zcrPPOO08PPPBAt20uX75cq1atCvcDJ4dvCj9Hrr322jSJas6cOVqxYoWefvrpHn/iuOWWW/Tkk0/qt3/7t7Vo0SJNnz5d+/bt08qVK/Xoo49q/fr1aUy5kdR58+bpy1/+si655BItWLBALS0t+ru/+ztNnDhRr7766kkdz+23365ly5bpAx/4gD7xiU/o8OHD+tu//VtNmzZNr7zyyglta968eWpsbNTSpUs1d+5cDR06tMfvXHzxxfq3f/u3rD9hlePqq6/WI488ouuvv14//OEP9YEPfECHDx/WG2+8oUceeURPP/20ZsyYofPOO0+/93u/p3vvvVft7e2aOXOmfvCDH5T1Tamurk533XWXrr32Wl1wwQVasGCB6uvrtWLFCnV2duqBBx6QJE2fPl3/8i//oj/8wz/UBRdcoJqaGl166aW9to/lRFI7Ojo0atQoffjDH9a5556rmpoaPfPMM/qv//ov/c3f/I0kadKkSZowYYL++I//WFu2bFFdXZ0ee+yxHv+2IEl33HGH5s2bp1/7tV/Txz72MbW2tuqee+7R1KlTtXfv3jKuGE7I6Qs+/eIrFUmdOnXqcX//8OHDxac//emiqampqKqqKn7zN3+zWLt2bY9IalEURUdHR3HrrbcWEydOLPr37180NTUVM2fOLL70pS8Vhw4dSr93IpHUb3zjG8VZZ51VVFZWFpMmTSqWLFmS4ptHk3TcuOHx9vMHP/hB8au/+qtF//79iwkTJhT/+I//WPzRH/1RMWDAgLK2ebTFixcXkoqHH374uPXp06cXw4cPt8d55Jh27NgR/l50rQ4dOlTceeedxdSpU4vKysqivr6+mD59evG5z32uaG9vT7+3f//+4pOf/GTR2NhYVFdXF5deemmxadMmG0k94sknnyxmzpxZDBw4sKirqyve+973Ft/61rdSfe/evcWCBQuKwYMH94honup9LIryIqkHDx4sbrnlluLcc88tamtri+rq6uLcc88t7r333m6/t2rVqmL27NlFTU1N0dTUVHz84x9P0eYlS5Z0+93HHnusmDx5clFZWVlMmTKlePzxx4uFCxcSSe0FFUXRy/+zCjjGhz70Ib322mvH/Ttx5Oabb9Y3vvENbdu2rcdSEx0dHWpoaNBXvvIV3XDDDadyd4FfKvybAnrVsUsWrFmzRt/73vd08cUXn9B2Dhw4oAcffFCXXXbZcdce+vGPf6yRI0fq4x//eM7uAr/0+KaAXtXc3KxFixbpzDPP1IYNG3Tffffp4MGDevnll4+bPT9WS0uLnnnmGT366KN64okn9NJLL+m8887r/R0HfknxD83oVZdccom+9a1vadu2baqsrNT73/9+feELXyirIUjSqlWrdOWVV2ro0KG6++67aQhAL+ObAgAg4d8UAAAJTQEAkJT9bwpHppuX0qfPyfeXo2fgHs+hQ4fCejSB5djZwMdy6xBF491+9evXL6y78RG3oN4ZZ8SXNjrnbttHr3p6PMOHDy9ZK7VA2xGDBw8O6znH7e5Rdy9ET0Y7MkO4lOPNOj7a8SZtlTt+27Zt4dgjK9eeDPfedE+Li66Xu5ZuNdjjPYznaNG+uf12T9eLHpvqPnPcfrvPjWjfOjs7w7FHHiAV4ZsCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACB5V9Y+cs9bPfoh8SczPsqXu5y1e+0oK+3GuhVEom27TL2b4+DmKTQ0NJSsuXWJ3vOe94T1mpqasB4ZNmxYWHfZ9ijP7x7I4uZQRPlx92S72trasO6Oy9Ujxz657VjROXOZe/fedPMBIrlzJFzeP5LzmeSuVc5+Sf6a5OKbAgAgoSkAABKaAgAgoSkAABKaAgAgoSkAAJKyI6ku1pYTmXNL5LpoZxRNc9FMFyWMlrl1kTi3FHMUa3OROGfUqFFhPXqs5ejRo8Oxrh7FL931cNe6o6MjrNfV1ZWsNTc3h2Oj5ZClOCbsYoIDBgwI6zlLULv4slvWO4p+urHu/RNx++0+F3KinS5K6+Q8KsC9B9y2cyOtDt8UAAAJTQEAkNAUAAAJTQEAkNAUAAAJTQEAkNAUAABJ2fMUXH48yvPnLgvsXjvKSruxTs78C5fhjpa/dq87aNCgsD58+PCwHi1RXVVVFY7NWQ45d7ljN5cgut4umx7NcXDj3VLm1dXVYd3NA4rmQbg5LW7Z7mjuh5t/4e7x6Hq7e9y9trtXouuVM89AiucauG3nLn0dzSs5Fctq800BAJDQFAAACU0BAJDQFAAACU0BAJDQFAAACU0BAJCUPU/BZYqjnHWUq5Xy11WPsukuR+32LeIywTnPgaivrw/HNjU1hXWXi4/23R2XmysQ5cOj+SySP273XILoert5Cu64cubDuDX03fsrejaHm4cwZMiQsL5jx46wHsmZs5Izj6cc0eeG+8xx1yMa747LzStx+xbV3X1WDr4pAAASmgIAIKEpAAASmgIAIKEpAAASmgIAIKEpAACSskOtLuPdm3nlnDXCXebX7XeUlXbzJ9wzD6LseU1NTTjWZeqjbUvxswPca7vjjl7bzTNw91lnZ2dYj7bvrofbdrR+f26mPuc+dc+/cPMUonr0rAXJz/OJzot777l7xT1PIeLuM/d8i+i13eeVq7tzGs1FcPdCOfimAABIaAoAgISmAABIaAoAgISmAABIaAoAgKTsSKpbGjiKaLn4l9t2zhLUuVFaF/2MuOWro+ini5a5bbtIanTcOcfsXjtnSW/JL2kcxRjb29vDse5eiO5xNzY3fhlFO905cUtrNzQ0lKytW7cuHOvik9FS6W6/cyKnTu62o1h27nL97jMreo+4WHU5+KYAAEhoCgCAhKYAAEhoCgCAhKYAAEhoCgCAhKYAAEjKnqfgctRR9tbNM8hZilmKl7mNctKSzxRHcjLzUjxPIWfp63LqOctbu32LuPPt5me4ORTRNXFjXcY72rY7LnfOcnLzbtluV4/uFXcvuHr0/nOfC7miJaZzlqd23Pl294r7XInO28GDB8Ox5eCbAgAgoSkAABKaAgAgoSkAABKaAgAgoSkAABKaAgAgKTuM67K1Uc7arZHfp0/cm3LqLm8czXGQ4uNyGe3GxsawPmLEiJI1N3fDvbYTXROXmXfPBogy+e5ecNuO5nZIcUa8N7ede86cnOdfuNx8xN3Dbm5H9CwH9752zxVw46O8v3vf53zeuTkpru5eO+d6loNvCgCAhKYAAEhoCgCAhKYAAEhoCgCAhKYAAEjKjqS6CFcUs3KRObeMbU58zEUFXQwxWqbWLU9dX18f1gcNGlSyVl1dHY51UVsXWY2276KAbsnjaN9y45N79+4N69F96PbbRQGjZaBzlwTft29fWI+Oq6OjIxzr6tE5z1la3m3bxXTdveKWiY4+V3Kj0TnLcrt6TtTW3Wfl4JsCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACApe56Cy+1G2Vo3V8Bxy0hH23dj3XFFOesoLyz5+RW7d+8+6f2K5jhI/rgjuctAR7n4aCllyc8bcXMooux67vLVOfNhXObe5eajeyk3m97S0lKy1traGo5180qi8+LOmXt/ubkd0WeSmyvgrkdUd2OdnM/a3NeW+KYAADgKTQEAkNAUAAAJTQEAkNAUAAAJTQEAkNAUAABJ2fMUXKY4yivnZOYlv764e7ZAJGdddZeT3rhxY1iPjquxsTEcO3To0LDunsewa9eukrXRo0eHY109Wvvf5dpdRtvNY4jmErg5Du4ej+q58xBynmGxffv2cOzq1avD+ptvvlmy5u7xnHPmuHk+TvS54+4zdz2i6+me2+HkPGci97NW4psCAOAoNAUAQEJTAAAkNAUAQEJTAAAkNAUAQFJ2ljNnSVa3BK6LUbl4WLQMrot3uX2Ltu3iesOGDQvrZ599dslaU1NTONYdl4vzReNXrlwZjn3ttdfCehSXdVFaF1kdO3ZsWI/u02hZbSlvCer9+/eHdRerdktUR/faT37yk3DsSy+9FNajiKOLH7s4eLSMent7ezjWfebkxICj6LLk3185y7C7ZbtdPTrnOfH8I/imAABIaAoAgISmAABIaAoAgISmAABIaAoAgISmAABIyg615swlyJnjkMvNcXBZ52ip5rq6unDs+PHjw/qQIUNK1lyef8yYMWHd5eKjeQzvvPNOOHb9+vVhffPmzSVrLS0t4Vg398MtSxzNNXBzUpyc+TBOW1tbWF+7dm3J2s6dO8Oxzc3NYX3AgAEnVZOkPXv2hPXocyP3erhMfjR3xM2Hce+f6Hq7e8HNkXD1yKn4rOWbAgAgoSkAABKaAgAgoSkAABKaAgAgoSkAABKaAgAgKXueQr9+/cJ6lK11a/u7uQROlIV2uV332lGeeffu3eHYHTt2hPX6+vqSNbf2/7Zt28L6wIEDw3r0vAa3hn6035K0devWkrWNGzeGY7ds2RLW3TMPRo4cWbLm9tvly6N7yWXmOzs7w7rLzW/atKlkzc2XiebaSNKaNWtK1tw97OaVuGcD5HDbzpkj4bYd3QvuPnJzINxnUm/PCeObAgAgoSkAABKaAgAgoSkAABKaAgAgoSkAABKaAgAgKXueQs5cApeddfMYctY2d2uTu21Ha7K73LvLpr/66qsla6+//no4NidTL0nV1dUnvW1Xj+YKTJo0KRzrrpfL80fXy11r9wyLaD6Au4fdcblcfDTvxL32W2+9FdbdfRpxz1uI9i33fZ+TyXf77e6z6PPQvT9ytu22n/tcD4lvCgCAo9AUAAAJTQEAkNAUAAAJTQEAkNAUAABJ2ZHUnPiXi2C5eFjOa7slpN1SzNFruyifW1o72raLKBZFEdbdksaDBw8O65H3vve9YX3nzp0la+3t7eHYGTNmnPS2Jam1tbVkzUWIXQQyulcqKyvDse56uPdIdD/kREqleKl0dw/v3bs3rEcRSXe+Xd3FfKP3iBvrlq7PiYW6e8V93kXHFS0XXi6+KQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAkrLnKeQsX30qlnONRJnj3KxzlB93cyBc1jnK7Dc2NoZjGxoawrrLxffr169k7fzzzw/Hzp07N6z/93//d8laW1tbONYt83z22WeH9WjpbJe5r62tDevROYuWIpekbdu2hfVov6V4noK7V8aMGRPWW1paStZyl/yOROdTypufJEl79uwpWctdHv6MM8r+6Dxh/fv3D+u9/XnKNwUAQEJTAAAkNAUAQEJTAAAkNAUAQEJTAAAkNAUAQFJ22DYnG+syvS7P39XVFdaj9cXdfrscdpQZdsflnhMRjXfZcjdHwtWj4xo3blw4Nsp/S9KZZ55ZslZXVxeOddn0TZs2hfXoerv8t+OeeRBx95lbYz96/sWBAwfCse64o9d2z+1w74HonLlr7T4X3BykaB6E+0xx5yxnnoLb7xynYv4E3xQAAAlNAQCQ0BQAAAlNAQCQ0BQAAAlNAQCQnLKls6P4mBvr6i4WF8XHcuNf0bZd5LSpqSmsR+PHjx8fjq2pqcmqDxs27KT2S5KqqqrCulu2O+L220U3o+tVX18fjnX3WRR3dRFgd1xu36IY8I4dO8KxLkpbUVFRsuaimb0Z03XLcrv4ZXSf5m47+lxxS4I77rxE9ymRVADAKUVTAAAkNAUAQEJTAAAkNAUAQEJTAAAkNAUAQFJ2qNXleqPsrFsit7q6Oqy7pYFzuExxVI+y/pJf/jo6py4f7s6ZmyMR5eZra2vDse56RPMcBg0aFI51cxzccTc0NJSsubkEbjnlHDnLPEtx5t7dK/v37w/rOdfL3QtR5t4dczR/QpI6OzvDepTZd59JOdx9lDuPIdq++5wuB98UAAAJTQEAkNAUAAAJTQEAkNAUAAAJTQEAkNAUAABJ2fMU3FrzEZcJduuH58xTcJlhtz5/lJuvq6sLx44aNSqsR+vzu227/LjL80evHa3dL0nDhw8P64MHDw7rkSFDhoR1l/GOjsvdZ26/o2077nq414723b2/2trawnr0HnHbjp6jIsW5+dxMfc68Enct3XMJcuZlOTnzN9w9Xg6+KQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAkrLnKeRkgl1u162h7/LM0fbd/Aq37Sj3G61DL/n1+6NnGjQ3N4djXa7dZZ2j3HzOPAMpPqfuPtq7d29Yd/nxSM595OrufLt5JR0dHWE9Om/RsxYkf1w51+vQoUNhPXr/uPlH7rXd+y+6V3LuIyf3uRzuXoquJ/MUAACnFE0BAJDQFAAACU0BAJDQFAAACU0BAJCUncvKWQ42Wuq1nG27aGcUbXMRLbdMdLSEtYtuuuWSo0idizDmxkYbGhpK1vr37x+OjaK0UhxTbG1tDce6OJ6LGEf3krsP3TLq0XLLbilmtxS6i5VG58VdL7dvUSS1T5/4fzfW19eH9d27d5estbe3n/R+ST6SGi3r7Y7LxWVz7oWce1iK7+PcOKzENwUAwFFoCgCAhKYAAEhoCgCAhKYAAEhoCgCAhKYAAEjKnqfQm/lwl+t1ud0oj+y27eZADB06tGRt7Nix4djGxsawHs1jGDlyZDjW5cNdznrUqFEla+6cueWSo3vF5ajdEtLuXojmpbg5EC67Hs0HcEsxu3M6fPjwsL59+/aSNbf0vJvHENXdOYvmIUjxe9PNEWpqagrrW7duDevRvBN3H7rjjsb35hLtUvx56u6zcvBNAQCQ0BQAAAlNAQCQ0BQAAAlNAQCQ0BQAAAlNAQCQvCvPU3DZ2f3794d1N0ciygzn5nabm5tL1lz+2+Xeoxy2G+ty1iNGjAjrUa7enTP32tG94q6lmwPhMvlRvba2Nhybc1xubf/cuTrR8zVaWlrCse6cRq/t7kM3F2fMmDEla26egXvegnvtaM6K+8xx1yO6nm6egpPz2qcC3xQAAAlNAQCQ0BQAAAlNAQCQ0BQAAAlNAQCQnLJIahTncxGq3KVkIy5mGC1fLcWxUxePdK89bNiwkjW3FHO0JLHkY4hR1NBtO4eL23V2doZ1t9xydK9UVVWFY90y6tF97OLJ7rXdeYnilTt37gzHuvjl3r17S9bcPe7ePw0NDSVro0ePDseuXbs2rEfnRMq7j10UN+KupXtvu3rkVLx3+aYAAEhoCgCAhKYAAEhoCgCAhKYAAEhoCgCAhKYAAEjKDsS6DPeBAwdK1vr16xeOdZlgl0fOmcfgjstlvCMub9za2lqyVlNTE46Nlt2W8vLKbnlrd06iuQRRJl6SOjo6wrrbt+hecksau7kd0b3ixjruekXZdzdXIOdece9ddz2i8ZMmTQrHOps2bTrpsblL00efSW6egltm3Y2Prlfust0S3xQAAEehKQAAEpoCACChKQAAEpoCACChKQAAEpoCACApe56Cy9xHeeTc9cNznsfg8uNuDkSUq3dr+7vM/a5du0rWXFbZcXM33HMLIm1tbWE9msfgXtedM8c9tyDinksQzVNw94LL+7t7vLfGuvFujoM77uhecPs9fPjwsO7mvET3qcvzR/OupLy5UbnzZaJ9y50vI/FNAQBwFJoCACChKQAAEpoCACChKQAAEpoCACChKQAAkrLnKbh8eZQ5dpletyZ7zprt7rXdOvbt7e0la24998bGxrAeZcBd/nvDhg1hfdCgQWE9Wk/eZZ337dsX1qNz7u4jlz13ovswd+5H9PyL3HXs3XGvX7++ZO3tt98Ox7r3T0NDQ8maO2fuXojmKbg5Ke69W19fH9aja+LeXzmfSW6s+8xx779o+/379w/HloNvCgCAhKYAAEhoCgCAhKYAAEhoCgCAhKYAAEjKjqS6eFgUhXJjXezN1aPXzll2W4pjc9u2bQvH7t69O6xHMcPq6upwrIvjuThsToQyiulK8Tl1cTwXqXNLGkfXxC2T3tXVFdZra2tL1kaMGBGOda/t4plRPYoXS34J6kgUw82t79ixIxzrrrWTs8S0u16uHsn9vOutsUfwTQEAkNAUAAAJTQEAkNAUAAAJTQEAkNAUAAAJTQEAkJQ9T8HlX3OWznbZdJepd9uPuOOKMvlu+eoxY8aE9Wi/hw0bFo51ojkQknTGGaUvvbseOfNO3Lbdkt85Szm7+8gtX93S0lKy5jL1bjnlIUOGhPUZM2aUrLl5Cm7ftm/fXrLm8vhuPk20bbdf7rXdfJmIm5Pi7pWo7q5H9N6T/D0evf9yl3CX+KYAADgKTQEAkNAUAAAJTQEAkNAUAAAJTQEAkNAUAABJ2fMUcnK97pkGbm1zl72Ncr2VlZXh2M7OzrDucvWRjRs3nvS23VyAnTt3hnWXlY6up3vtkSNHhvV+/fqVrOXkvyV/L40aNeqkx7pnPUT3UvSshXJe283PiOYDuHvBvb+ie2XAgAHhWPdMhGjuh3uGhHvtqqqqsB7dS21tbeFY9x6I3j9ufoXbtpvHEF2vnDlbafvZWwAA/MKgKQAAEpoCACChKQAAEpoCACChKQAAkrIjqTlRQbcUbM5SsZKPgOVsO4dbijmqu4ijW3Y4ioU6Lj7pjstFIHO4qG1NTU3JmoswOtFy5i667M5JfX19WI+OK/d6RPXcaHS0lHl0TJK/hwcOHBjWo33LiZw6ufe/u5eiqK6Ls5aDbwoAgISmAABIaAoAgISmAABIaAoAgISmAABIaAoAgKTsUKvLrkf5cTcPwWXPnSgX3Jvbdudk+/btYb2pqalk7ayzzjrp/ZL8vkUZ8A0bNoRj3XLJUea+sbExHDt48OCwnrOUuVsau66uLqxHuXi337neeeedkrX169eHY908hs2bN5estbS0hGPffvvtsD5u3LiSNTc3w92H0RwIKf7ccfOunOj94z5z3LyqoijCejSHImd+0hF8UwAAJDQFAEBCUwAAJDQFAEBCUwAAJDQFAEBCUwAAJGXPU3D515znKbi1y3PWNnfrpuc868Gt5+6y0FEG3GWZGxoawrq7XlHe353vjRs3hvUoN+8y9ZWVlWHdZduj43LnxD1vIVrHfuTIkeFYd1zuuQRR3c1DcPdSdF7Gjh0bjq2urj7p+p49e8KxLu/v7lM3LyXntaPnFrjPhdx5Crlzrxy+KQAAEpoCACChKQAAEpoCACChKQAAEpoCACApO5Kas1SziwK6aJmLlUYRLTfWvXa0bbfUsoukbtu2rWTNRTdramrCuovFRfURI0aEY931jCJ3nZ2d4Vh3n7mls6Pop9vvnCWL29rawrEHDhwI624Z6GjJ8alTp4Zj3b0QRUPd8u85cfMtW7aEY905cec84vbbxUYj7h519ZzXdsdVDr4pAAASmgIAIKEpAAASmgIAIKEpAAASmgIAIKEpAACSsucpuJz1qcjH9sa23VwBl02PuBy1E82hcBlsV89ZMry9vf2kx0rxcsmDBw8Ox7qMdrR8tSQNGjSoZM3l9d2y3E1NTSVrbt6Iy6a7OS/ROd+8eXM4dtOmTWF9//79JWtuWW437yTatnv/uGvt3rvRvrl72M2XiT5XcpYql/y+RXOn3LbLwTcFAEBCUwAAJDQFAEBCUwAAJDQFAEBCUwAAJDQFAEBS9jwFl52NMsMuTxw9i0HKex5DTl7fvbbLcEd5YinOtrtzEq2BL/njjo7L7bfLYUf5c3dcbl6Je/6Fmy8Q2bVrV1g/44zSb5eDBw+GY917wM01iLYfzQWQfOa+tbW1ZC3neQlSfC+4+2jnzp1h3Z3zHDlzo3Ke/yL590jOa5eDbwoAgISmAABIaAoAgISmAABIaAoAgISmAABIaAoAgKTseQpubXOXhe5NOXMkXB45ygy7sTmZYfdMA3c9XH48UlVVFdbdXILoXoiy/pK/Xu4+q62tLVlzzzRw1zN6hoWbs+KOyz2vJLqe7py4eynK+7t72M0liM6Lm3/knhni5jlEz1Nw97i7F6J6bz5bRoqvibuPysE3BQBAQlMAACQ0BQBAQlMAACQ0BQBAQlMAACRlR1Jd/CuKYblY28CBA8O6i1lF0TYXgXRxvijG6I7LRSCj/Y6WM5b8frtzNmTIkJI1d61dlDC6F1x000Vto8ipFC8j3dHRkbXtnHvcRSDd+Oh6u7ire38NGjSoZG3NmjXhWBd9bmhoKFlbuXJlODbnfS/F+xbFVaW8yKq7lrnLw0fjc6LoR/BNAQCQ0BQAAAlNAQCQ0BQAAAlNAQCQ0BQAAAlNAQCQlD1PwWWho3xsZWVlONbl4uvr68N6lOnPnacQZaHr6urCsU60ZLE7Zy7vH+X1pficu5y1y/NHufg+feL/HeKy6W7+xrBhw0rWBg8eHI51Ge/onOZer2iugBQfl5sP4+Z+rFixomTNXQ+335s2bSpZc0tju+PKmfPiPnPc50JvzhXImcfg3l/l4JsCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACApe55Czjr2LjvrctQujxzl4t1a8m7+RWTfvn1h3R1XJJrDIPkctTvnUa7e5aRHjx4d1l2+POLmSLjzEt2Hbts1NTVhPZrn4OasNDU1hfXo+RZSfJ+6+/Ctt94K67t27SpZc9dy9+7dYX379u0la+6ZBm6OhBPNRXDve/ceyOHuQ1ePnuWQ8947gm8KAICEpgAASGgKAICEpgAASGgKAICEpgAASN6VSGoUoZJ8dDNnieqKioqw7uJ8UaTVxUJzIqkurude29m2bdtJv7bT3t5eslZdXR2OdUsxu6XQo+udGyGOllHPiU1Lft+iiKSLMO7cuTOsR+/t6FpK0vr168N6tDy2228XC62qqgrr0TVxkVQX7Yzq7vPOLdvtYtfR0tnunJaDbwoAgISmAABIaAoAgISmAABIaAoAgISmAABIaAoAgKTseQrRUsuSNGPGjJI1l3V28xCiXK6Ul9l3yyVHOWt3TnKWv3Y56igznys6ZsnPY4jy4xMmTAjHuvkwOUudu3kI0RLSTrSstuTnMbh5Cjn5czf3o6WlpWRtzZo14Vi3LHfO8tcNDQ1h3Z2T6LhzlqeW4vvQfV45bm5VhHkKAIBTiqYAAEhoCgCAhKYAAEhoCgCAhKYAAEhoCgCApOx5Cr/7u78b1qNc79tvvx2OvfDCC8N6nz5x73rnnXdK1tatW3fSY6V4PsDu3bvDsXv27AnrUZ7f5Y1dXt/lrKPtR8/GkPLmhWzfvj2su/128xiiuptL4OaVdHR0lKy5NfJzn7eQ84yLaL8lae3atSVr7nkJ7l6Jnn/hzrfbtpsDET3zwM2NynnmgRvrPs/ceyAanzPHIW0/ewsAgF8YNAUAQEJTAAAkNAUAQEJTAAAkNAUAQEJTAAAkZc9TGDlyZFh//fXXS9Zctjxaz12SpkyZEtaHDRtWsnbmmWeGY1etWhXWo4z3pk2bwrEuZx2t7+9y6bnPW4jmGkT57nJEcyDcOXPPcoiutRRnvF0u3omuycaNG8Ox7lkOQ4YMCevRnBc3B6K1tTWsr169+qReV/JzVqJ5Ci5T77bt7tMoz+/OWc4zEdy1dvMQ3PyL6P11Kp6zwjcFAEBCUwAAJDQFAEBCUwAAJDQFAEBCUwAAJGVHUl3kbvPmzSVrF1xwQTjWRbSef/75sL5jx46StbPOOisc+wd/8AdhvbGxsWTNxSv/6q/+Kqy/+OKLJWv79u0Lx7pz5pbvzeGW9Xb7FnFRQRcr3bVrV8laTU1NONbFXaN4pYtPunMWvX8ctzy8e+2IW9LbHXd0vdx94iKrbgnqKNrp4qw558xx58y9d6PIa319/Unt09H4pgAASGgKAICEpgAASGgKAICEpgAASGgKAICEpgAASCoKtwYzAOCXBt8UAAAJTQEAkNAUAAAJTQEAkNAUAAAJTQEAkNAUAAAJTQEAkNAUAADJ/wM483y+8g5+QAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_predictions(best_model, X_test, y_test, label_encoder, X_original):\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    random_indices = np.random.randint(0, len(y_test), 5)\n",
    "    \n",
    "    for idx in random_indices:\n",
    "        original_image = X_original[idx].reshape(48, 48)  # Reshape to 48x48\n",
    "        plt.imshow(original_image, cmap='gray')\n",
    "        plt.title(f\"True: {label_encoder.inverse_transform([y_test[idx]])[0]}, \"\n",
    "                  f\"Predicted: {label_encoder.inverse_transform([y_pred[idx]])[0]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "visualize_predictions(best_model, X_test, y_test, label_encoder, X_original)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
