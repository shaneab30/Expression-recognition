{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pickle import dump, load\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_images(images_folder, save_file_to=None):\n",
    "    \n",
    "#     X_original = []\n",
    "#     X = []\n",
    "#     y = []\n",
    "    \n",
    "#     for subdir, dirs, files in os.walk(images_folder):\n",
    "#         for file in files:\n",
    "#             if file.endswith(('jpg', 'jpeg', 'png')):\n",
    "#                 img_path = os.path.join(subdir, file)\n",
    "#                 label = os.path.basename(subdir)\n",
    "                \n",
    "#                 image = Image.open(img_path).convert('L')\n",
    "#                 image = image.resize((64, 64))\n",
    "#                 X_original.append(np.array(image).flatten())\n",
    "#                 X.append(np.array(image).flatten())\n",
    "#                 y.append(label)\n",
    "                \n",
    "#     if save_file_to:\n",
    "#         with open(save_file_to, \"wb\") as f:\n",
    "#             dump((X, y), f, protocol=5)\n",
    "                \n",
    "#     return np.array(X_original), np.array(X), np.array(y)\n",
    "\n",
    "# images_folder = '/Users/shaneab/Projects/Machine Learning/Expression recognition/jonathanheix dataset/images'\n",
    "# dataset_file = \"dataset_dump.pkl\"\n",
    "\n",
    "# # Load images and save the dataset for reuse\n",
    "# X_original, X, y = load_images(images_folder, save_file_to=dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " 'happy',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"dataset_dump.pkl\", \"rb\") as f:\n",
    "    X_original,X,y = load(f)\n",
    "    \n",
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessing_data(X, y, save_file_to=None):\n",
    "#     # Normalize pixel values\n",
    "#     X = X / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "#     # Encode labels\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "#     # Dimensionality reduction with PCA\n",
    "#     pca = PCA(n_components=100)\n",
    "#     X_reduced = pca.fit_transform(X)\n",
    "    \n",
    "#     # Standardize the data\n",
    "#     scaler = StandardScaler()\n",
    "#     X_scaled = scaler.fit_transform(X_reduced)\n",
    "    \n",
    "#     if save_file_to:\n",
    "#         with open(save_file_to, \"wb\") as f:\n",
    "#             dump((X_scaled, y_encoded, label_encoder, pca, scaler), f, protocol=5)\n",
    "    \n",
    "#     return X_scaled, y_encoded, label_encoder, pca, scaler\n",
    "\n",
    "# X_scaled, y_encoded, label_encoder, pca, scaler = preprocessing_data(X, y, save_file_to=\"labelencoder_standardscaler_pca_normalizers_dump.pkl\")\n",
    "\n",
    "# # with open(\"svc_standardscaler_gridsearch_normalizers_dump.pkl\", \"wb\") as f:\n",
    "# #     dump((label_encoder, pca, scaler), f, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labelencoder_standardscaler_pca_normalizers_dump.pkl\", \"rb\") as f:\n",
    "    X_scaled, y_encoded, label_encoder, pca, scaler = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.58      0.07      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.46      0.10      0.17      1015\n",
      "       happy       0.33      0.87      0.48      1824\n",
      "     neutral       0.39      0.22      0.28      1260\n",
      "         sad       0.36      0.23      0.28      1226\n",
      "    surprise       0.59      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.27      0.26      7178\n",
      "weighted avg       0.42      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.70      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.51      0.10      0.16      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.40      0.21      0.28      1260\n",
      "         sad       0.39      0.22      0.28      1226\n",
      "    surprise       0.59      0.44      0.51       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.42      0.28      0.26      7178\n",
      "weighted avg       0.45      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.75      0.06      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.54      0.10      0.17      1015\n",
      "       happy       0.33      0.89      0.48      1824\n",
      "     neutral       0.40      0.21      0.28      1260\n",
      "         sad       0.39      0.22      0.28      1226\n",
      "    surprise       0.60      0.45      0.51       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.43      0.28      0.26      7178\n",
      "weighted avg       0.46      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.62      0.07      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.43      0.10      0.16      1015\n",
      "       happy       0.33      0.88      0.48      1824\n",
      "     neutral       0.38      0.22      0.28      1260\n",
      "         sad       0.38      0.21      0.27      1226\n",
      "    surprise       0.60      0.41      0.49       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.27      0.26      7178\n",
      "weighted avg       0.42      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.76      0.07      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.50      0.09      0.15      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.39      0.20      0.27      1260\n",
      "         sad       0.39      0.21      0.27      1226\n",
      "    surprise       0.60      0.42      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.42      0.27      0.26      7178\n",
      "weighted avg       0.46      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.84      0.07      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.58      0.10      0.17      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.39      0.21      0.28      1260\n",
      "         sad       0.39      0.21      0.27      1226\n",
      "    surprise       0.60      0.42      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.45      0.27      0.26      7178\n",
      "weighted avg       0.48      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.59      0.07      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.40      0.09      0.14      1015\n",
      "       happy       0.33      0.88      0.48      1824\n",
      "     neutral       0.41      0.23      0.30      1260\n",
      "         sad       0.36      0.22      0.27      1226\n",
      "    surprise       0.57      0.42      0.49       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.38      0.27      0.26      7178\n",
      "weighted avg       0.42      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.73      0.07      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.48      0.09      0.16      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.40      0.21      0.28      1260\n",
      "         sad       0.38      0.21      0.27      1226\n",
      "    surprise       0.59      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.42      0.27      0.26      7178\n",
      "weighted avg       0.45      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.75      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.53      0.10      0.17      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.41      0.21      0.28      1260\n",
      "         sad       0.38      0.21      0.27      1226\n",
      "    surprise       0.59      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.43      0.27      0.26      7178\n",
      "weighted avg       0.46      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.58      0.06      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.46      0.12      0.19      1015\n",
      "       happy       0.34      0.88      0.49      1824\n",
      "     neutral       0.38      0.22      0.28      1260\n",
      "         sad       0.36      0.23      0.28      1226\n",
      "    surprise       0.60      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.28      0.26      7178\n",
      "weighted avg       0.42      0.37      0.32      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.72      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.53      0.11      0.18      1015\n",
      "       happy       0.33      0.89      0.48      1824\n",
      "     neutral       0.39      0.21      0.28      1260\n",
      "         sad       0.39      0.23      0.29      1226\n",
      "    surprise       0.62      0.44      0.51       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.43      0.28      0.26      7178\n",
      "weighted avg       0.46      0.38      0.32      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.76      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.60      0.10      0.18      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.41      0.21      0.28      1260\n",
      "         sad       0.40      0.23      0.29      1226\n",
      "    surprise       0.62      0.45      0.52       776\n",
      "\n",
      "    accuracy                           0.38      7178\n",
      "   macro avg       0.44      0.28      0.27      7178\n",
      "weighted avg       0.48      0.38      0.32      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.45      0.10      0.16      1015\n",
      "       happy       0.34      0.88      0.49      1824\n",
      "     neutral       0.37      0.23      0.28      1260\n",
      "         sad       0.36      0.21      0.26      1226\n",
      "    surprise       0.59      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.27      0.26      7178\n",
      "weighted avg       0.42      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.82      0.06      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.49      0.09      0.16      1015\n",
      "       happy       0.33      0.89      0.48      1824\n",
      "     neutral       0.40      0.22      0.29      1260\n",
      "         sad       0.37      0.21      0.27      1226\n",
      "    surprise       0.60      0.44      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.43      0.27      0.26      7178\n",
      "weighted avg       0.46      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.87      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.53      0.09      0.16      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.40      0.22      0.29      1260\n",
      "         sad       0.38      0.21      0.27      1226\n",
      "    surprise       0.61      0.43      0.51       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.45      0.27      0.26      7178\n",
      "weighted avg       0.48      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.65      0.07      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.42      0.09      0.15      1015\n",
      "       happy       0.33      0.88      0.48      1824\n",
      "     neutral       0.38      0.21      0.27      1260\n",
      "         sad       0.36      0.22      0.27      1226\n",
      "    surprise       0.61      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.39      0.27      0.26      7178\n",
      "weighted avg       0.42      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.66      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.44      0.08      0.13      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.39      0.21      0.27      1260\n",
      "         sad       0.38      0.22      0.28      1226\n",
      "    surprise       0.58      0.42      0.49       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.40      0.27      0.25      7178\n",
      "weighted avg       0.43      0.37      0.30      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.79      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.52      0.09      0.15      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.41      0.21      0.28      1260\n",
      "         sad       0.38      0.21      0.27      1226\n",
      "    surprise       0.60      0.44      0.51       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.43      0.27      0.26      7178\n",
      "weighted avg       0.46      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.68      0.07      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.44      0.10      0.16      1015\n",
      "       happy       0.33      0.88      0.48      1824\n",
      "     neutral       0.39      0.22      0.28      1260\n",
      "         sad       0.37      0.22      0.28      1226\n",
      "    surprise       0.59      0.41      0.48       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.40      0.27      0.26      7178\n",
      "weighted avg       0.43      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.80      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.50      0.10      0.16      1015\n",
      "       happy       0.33      0.89      0.48      1824\n",
      "     neutral       0.40      0.21      0.28      1260\n",
      "         sad       0.39      0.23      0.29      1226\n",
      "    surprise       0.60      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.43      0.27      0.26      7178\n",
      "weighted avg       0.46      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.83      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.53      0.09      0.16      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.42      0.20      0.27      1260\n",
      "         sad       0.37      0.21      0.27      1226\n",
      "    surprise       0.60      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.44      0.27      0.26      7178\n",
      "weighted avg       0.47      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.68      0.07      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.44      0.10      0.16      1015\n",
      "       happy       0.33      0.88      0.48      1824\n",
      "     neutral       0.39      0.22      0.28      1260\n",
      "         sad       0.37      0.22      0.28      1226\n",
      "    surprise       0.59      0.41      0.48       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.40      0.27      0.26      7178\n",
      "weighted avg       0.43      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.80      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.50      0.10      0.16      1015\n",
      "       happy       0.33      0.89      0.48      1824\n",
      "     neutral       0.40      0.21      0.28      1260\n",
      "         sad       0.39      0.23      0.29      1226\n",
      "    surprise       0.60      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.43      0.27      0.26      7178\n",
      "weighted avg       0.46      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.83      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.53      0.09      0.16      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.42      0.20      0.27      1260\n",
      "         sad       0.37      0.21      0.27      1226\n",
      "    surprise       0.60      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.44      0.27      0.26      7178\n",
      "weighted avg       0.47      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.70      0.07      0.13       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.44      0.10      0.16      1015\n",
      "       happy       0.33      0.87      0.48      1824\n",
      "     neutral       0.37      0.22      0.28      1260\n",
      "         sad       0.33      0.19      0.24      1226\n",
      "    surprise       0.55      0.43      0.48       776\n",
      "\n",
      "    accuracy                           0.36      7178\n",
      "   macro avg       0.39      0.27      0.25      7178\n",
      "weighted avg       0.42      0.36      0.30      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.84      0.06      0.12       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.54      0.10      0.16      1015\n",
      "       happy       0.33      0.89      0.48      1824\n",
      "     neutral       0.39      0.21      0.27      1260\n",
      "         sad       0.37      0.22      0.28      1226\n",
      "    surprise       0.58      0.44      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.43      0.27      0.26      7178\n",
      "weighted avg       0.47      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.88      0.06      0.11       970\n",
      "     disgust       0.00      0.00      0.00       107\n",
      "        fear       0.54      0.09      0.15      1015\n",
      "       happy       0.33      0.90      0.48      1824\n",
      "     neutral       0.40      0.21      0.28      1260\n",
      "         sad       0.37      0.21      0.27      1226\n",
      "    surprise       0.59      0.43      0.50       776\n",
      "\n",
      "    accuracy                           0.37      7178\n",
      "   macro avg       0.44      0.27      0.26      7178\n",
      "weighted avg       0.47      0.37      0.31      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.41      0.18      0.25       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.41      0.22      0.29      1015\n",
      "       happy       0.40      0.75      0.52      1824\n",
      "     neutral       0.36      0.32      0.34      1260\n",
      "         sad       0.33      0.28      0.31      1226\n",
      "    surprise       0.67      0.50      0.57       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.51      0.35      0.38      7178\n",
      "weighted avg       0.42      0.41      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.54      0.17      0.25       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.49      0.23      0.31      1015\n",
      "       happy       0.39      0.80      0.53      1824\n",
      "     neutral       0.39      0.33      0.36      1260\n",
      "         sad       0.36      0.30      0.33      1226\n",
      "    surprise       0.71      0.52      0.60       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.36      0.39      7178\n",
      "weighted avg       0.46      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.57      0.15      0.24       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.53      0.23      0.32      1015\n",
      "       happy       0.39      0.82      0.53      1824\n",
      "     neutral       0.41      0.33      0.37      1260\n",
      "         sad       0.37      0.30      0.33      1226\n",
      "    surprise       0.71      0.52      0.60       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.37      0.39      7178\n",
      "weighted avg       0.48      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.42      0.17      0.24       970\n",
      "     disgust       1.00      0.19      0.31       107\n",
      "        fear       0.42      0.22      0.29      1015\n",
      "       happy       0.39      0.75      0.52      1824\n",
      "     neutral       0.39      0.33      0.36      1260\n",
      "         sad       0.33      0.28      0.31      1226\n",
      "    surprise       0.65      0.51      0.57       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.51      0.35      0.37      7178\n",
      "weighted avg       0.43      0.41      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.49      0.16      0.24       970\n",
      "     disgust       1.00      0.20      0.33       107\n",
      "        fear       0.51      0.22      0.31      1015\n",
      "       happy       0.39      0.81      0.53      1824\n",
      "     neutral       0.41      0.33      0.37      1260\n",
      "         sad       0.37      0.30      0.33      1226\n",
      "    surprise       0.67      0.51      0.58       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.55      0.36      0.38      7178\n",
      "weighted avg       0.46      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.55      0.14      0.22       970\n",
      "     disgust       1.00      0.20      0.33       107\n",
      "        fear       0.51      0.22      0.31      1015\n",
      "       happy       0.38      0.83      0.53      1824\n",
      "     neutral       0.42      0.32      0.37      1260\n",
      "         sad       0.39      0.31      0.35      1226\n",
      "    surprise       0.70      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.36      0.39      7178\n",
      "weighted avg       0.47      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.42      0.15      0.22       970\n",
      "     disgust       1.00      0.13      0.23       107\n",
      "        fear       0.44      0.21      0.29      1015\n",
      "       happy       0.40      0.78      0.52      1824\n",
      "     neutral       0.39      0.33      0.36      1260\n",
      "         sad       0.34      0.29      0.31      1226\n",
      "    surprise       0.65      0.50      0.57       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.52      0.34      0.36      7178\n",
      "weighted avg       0.43      0.41      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.52      0.14      0.22       970\n",
      "     disgust       1.00      0.14      0.25       107\n",
      "        fear       0.52      0.21      0.29      1015\n",
      "       happy       0.39      0.82      0.53      1824\n",
      "     neutral       0.41      0.33      0.37      1260\n",
      "         sad       0.36      0.31      0.33      1226\n",
      "    surprise       0.69      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.55      0.35      0.37      7178\n",
      "weighted avg       0.46      0.43      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.56      0.13      0.21       970\n",
      "     disgust       1.00      0.16      0.27       107\n",
      "        fear       0.54      0.21      0.30      1015\n",
      "       happy       0.39      0.84      0.53      1824\n",
      "     neutral       0.41      0.32      0.36      1260\n",
      "         sad       0.37      0.31      0.34      1226\n",
      "    surprise       0.69      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.36      0.37      7178\n",
      "weighted avg       0.48      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.38      0.15      0.21       970\n",
      "     disgust       1.00      0.19      0.31       107\n",
      "        fear       0.43      0.23      0.30      1015\n",
      "       happy       0.39      0.76      0.52      1824\n",
      "     neutral       0.36      0.32      0.34      1260\n",
      "         sad       0.34      0.28      0.31      1226\n",
      "    surprise       0.66      0.52      0.58       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.51      0.35      0.37      7178\n",
      "weighted avg       0.42      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.51      0.15      0.23       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.49      0.22      0.31      1015\n",
      "       happy       0.39      0.81      0.52      1824\n",
      "     neutral       0.40      0.32      0.36      1260\n",
      "         sad       0.36      0.28      0.31      1226\n",
      "    surprise       0.67      0.53      0.59       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.54      0.36      0.38      7178\n",
      "weighted avg       0.45      0.42      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.57      0.14      0.22       970\n",
      "     disgust       1.00      0.20      0.33       107\n",
      "        fear       0.53      0.22      0.31      1015\n",
      "       happy       0.38      0.83      0.52      1824\n",
      "     neutral       0.41      0.33      0.36      1260\n",
      "         sad       0.38      0.29      0.33      1226\n",
      "    surprise       0.69      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.36      0.38      7178\n",
      "weighted avg       0.48      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.45      0.15      0.23       970\n",
      "     disgust       1.00      0.18      0.30       107\n",
      "        fear       0.45      0.22      0.30      1015\n",
      "       happy       0.40      0.78      0.52      1824\n",
      "     neutral       0.38      0.32      0.35      1260\n",
      "         sad       0.34      0.30      0.32      1226\n",
      "    surprise       0.68      0.51      0.58       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.53      0.35      0.37      7178\n",
      "weighted avg       0.44      0.41      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.52      0.14      0.23       970\n",
      "     disgust       1.00      0.20      0.33       107\n",
      "        fear       0.52      0.22      0.31      1015\n",
      "       happy       0.39      0.83      0.53      1824\n",
      "     neutral       0.42      0.33      0.37      1260\n",
      "         sad       0.37      0.31      0.34      1226\n",
      "    surprise       0.71      0.53      0.61       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.37      0.39      7178\n",
      "weighted avg       0.47      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.15      0.23       970\n",
      "     disgust       1.00      0.19      0.31       107\n",
      "        fear       0.55      0.21      0.31      1015\n",
      "       happy       0.39      0.83      0.53      1824\n",
      "     neutral       0.40      0.32      0.36      1260\n",
      "         sad       0.38      0.31      0.34      1226\n",
      "    surprise       0.70      0.54      0.61       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.36      0.38      7178\n",
      "weighted avg       0.48      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.16      0.24       970\n",
      "     disgust       1.00      0.15      0.26       107\n",
      "        fear       0.44      0.22      0.29      1015\n",
      "       happy       0.40      0.79      0.53      1824\n",
      "     neutral       0.40      0.32      0.35      1260\n",
      "         sad       0.37      0.32      0.34      1226\n",
      "    surprise       0.70      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.54      0.36      0.37      7178\n",
      "weighted avg       0.45      0.42      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.56      0.13      0.22       970\n",
      "     disgust       1.00      0.17      0.29       107\n",
      "        fear       0.50      0.21      0.29      1015\n",
      "       happy       0.39      0.83      0.53      1824\n",
      "     neutral       0.41      0.31      0.35      1260\n",
      "         sad       0.38      0.33      0.35      1226\n",
      "    surprise       0.69      0.54      0.61       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.36      0.38      7178\n",
      "weighted avg       0.47      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.58      0.12      0.20       970\n",
      "     disgust       1.00      0.17      0.29       107\n",
      "        fear       0.54      0.21      0.31      1015\n",
      "       happy       0.39      0.85      0.53      1824\n",
      "     neutral       0.41      0.30      0.34      1260\n",
      "         sad       0.40      0.34      0.37      1226\n",
      "    surprise       0.69      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.36      0.38      7178\n",
      "weighted avg       0.48      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.14      0.22       970\n",
      "     disgust       1.00      0.11      0.20       107\n",
      "        fear       0.45      0.21      0.29      1015\n",
      "       happy       0.39      0.80      0.52      1824\n",
      "     neutral       0.40      0.33      0.36      1260\n",
      "         sad       0.36      0.29      0.32      1226\n",
      "    surprise       0.66      0.50      0.57       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.53      0.34      0.35      7178\n",
      "weighted avg       0.44      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.55      0.12      0.20       970\n",
      "     disgust       1.00      0.11      0.20       107\n",
      "        fear       0.51      0.21      0.29      1015\n",
      "       happy       0.38      0.84      0.53      1824\n",
      "     neutral       0.42      0.33      0.37      1260\n",
      "         sad       0.39      0.31      0.34      1226\n",
      "    surprise       0.67      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.35      0.36      7178\n",
      "weighted avg       0.47      0.43      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.63      0.13      0.21       970\n",
      "     disgust       1.00      0.14      0.25       107\n",
      "        fear       0.54      0.20      0.29      1015\n",
      "       happy       0.38      0.85      0.53      1824\n",
      "     neutral       0.42      0.33      0.37      1260\n",
      "         sad       0.39      0.31      0.34      1226\n",
      "    surprise       0.67      0.53      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.58      0.35      0.37      7178\n",
      "weighted avg       0.49      0.43      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.14      0.22       970\n",
      "     disgust       1.00      0.11      0.20       107\n",
      "        fear       0.45      0.21      0.29      1015\n",
      "       happy       0.39      0.80      0.52      1824\n",
      "     neutral       0.40      0.33      0.36      1260\n",
      "         sad       0.36      0.29      0.32      1226\n",
      "    surprise       0.66      0.50      0.57       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.53      0.34      0.35      7178\n",
      "weighted avg       0.44      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.55      0.12      0.20       970\n",
      "     disgust       1.00      0.11      0.20       107\n",
      "        fear       0.51      0.21      0.29      1015\n",
      "       happy       0.38      0.84      0.53      1824\n",
      "     neutral       0.42      0.33      0.37      1260\n",
      "         sad       0.39      0.31      0.34      1226\n",
      "    surprise       0.67      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.35      0.36      7178\n",
      "weighted avg       0.47      0.43      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.63      0.13      0.21       970\n",
      "     disgust       1.00      0.14      0.25       107\n",
      "        fear       0.54      0.20      0.29      1015\n",
      "       happy       0.38      0.85      0.53      1824\n",
      "     neutral       0.42      0.33      0.37      1260\n",
      "         sad       0.39      0.31      0.34      1226\n",
      "    surprise       0.67      0.53      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.58      0.35      0.37      7178\n",
      "weighted avg       0.49      0.43      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.48      0.15      0.22       970\n",
      "     disgust       1.00      0.08      0.16       107\n",
      "        fear       0.44      0.21      0.28      1015\n",
      "       happy       0.39      0.78      0.52      1824\n",
      "     neutral       0.39      0.34      0.37      1260\n",
      "         sad       0.35      0.28      0.31      1226\n",
      "    surprise       0.65      0.52      0.58       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.53      0.34      0.35      7178\n",
      "weighted avg       0.44      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.55      0.13      0.22       970\n",
      "     disgust       1.00      0.11      0.20       107\n",
      "        fear       0.53      0.21      0.31      1015\n",
      "       happy       0.38      0.81      0.52      1824\n",
      "     neutral       0.41      0.32      0.36      1260\n",
      "         sad       0.38      0.31      0.34      1226\n",
      "    surprise       0.68      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.56      0.35      0.36      7178\n",
      "weighted avg       0.47      0.42      0.39      7178\n",
      "\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.13      0.21       970\n",
      "     disgust       1.00      0.08      0.16       107\n",
      "        fear       0.55      0.20      0.29      1015\n",
      "       happy       0.38      0.83      0.52      1824\n",
      "     neutral       0.42      0.32      0.37      1260\n",
      "         sad       0.39      0.31      0.35      1226\n",
      "    surprise       0.65      0.53      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.34      0.35      7178\n",
      "weighted avg       0.48      0.43      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.35      0.19      0.24       970\n",
      "     disgust       0.93      0.24      0.39       107\n",
      "        fear       0.42      0.25      0.31      1015\n",
      "       happy       0.40      0.76      0.52      1824\n",
      "     neutral       0.38      0.32      0.34      1260\n",
      "         sad       0.35      0.27      0.31      1226\n",
      "    surprise       0.69      0.49      0.57       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.50      0.36      0.38      7178\n",
      "weighted avg       0.42      0.41      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.18      0.26       970\n",
      "     disgust       0.93      0.24      0.39       107\n",
      "        fear       0.48      0.24      0.32      1015\n",
      "       happy       0.40      0.81      0.54      1824\n",
      "     neutral       0.39      0.33      0.36      1260\n",
      "         sad       0.36      0.27      0.31      1226\n",
      "    surprise       0.70      0.51      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.53      0.37      0.39      7178\n",
      "weighted avg       0.45      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.51      0.17      0.25       970\n",
      "     disgust       0.93      0.25      0.40       107\n",
      "        fear       0.52      0.24      0.33      1015\n",
      "       happy       0.39      0.82      0.53      1824\n",
      "     neutral       0.40      0.32      0.35      1260\n",
      "         sad       0.38      0.29      0.33      1226\n",
      "    surprise       0.70      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.55      0.37      0.40      7178\n",
      "weighted avg       0.46      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.16      0.23       970\n",
      "     disgust       1.00      0.23      0.38       107\n",
      "        fear       0.43      0.24      0.31      1015\n",
      "       happy       0.39      0.73      0.51      1824\n",
      "     neutral       0.36      0.31      0.34      1260\n",
      "         sad       0.33      0.30      0.32      1226\n",
      "    surprise       0.68      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.51      0.36      0.38      7178\n",
      "weighted avg       0.42      0.41      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.50      0.16      0.24       970\n",
      "     disgust       1.00      0.21      0.35       107\n",
      "        fear       0.50      0.24      0.32      1015\n",
      "       happy       0.39      0.78      0.52      1824\n",
      "     neutral       0.40      0.33      0.36      1260\n",
      "         sad       0.37      0.32      0.34      1226\n",
      "    surprise       0.68      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.55      0.37      0.39      7178\n",
      "weighted avg       0.46      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Accuracy: 0.44\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.57      0.15      0.24       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.55      0.23      0.33      1015\n",
      "       happy       0.39      0.82      0.53      1824\n",
      "     neutral       0.42      0.34      0.38      1260\n",
      "         sad       0.39      0.34      0.36      1226\n",
      "    surprise       0.69      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.44      7178\n",
      "   macro avg       0.57      0.37      0.40      7178\n",
      "weighted avg       0.49      0.44      0.41      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.43      0.16      0.23       970\n",
      "     disgust       1.00      0.16      0.27       107\n",
      "        fear       0.43      0.22      0.29      1015\n",
      "       happy       0.40      0.76      0.52      1824\n",
      "     neutral       0.38      0.33      0.35      1260\n",
      "         sad       0.33      0.29      0.30      1226\n",
      "    surprise       0.67      0.52      0.58       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.52      0.35      0.36      7178\n",
      "weighted avg       0.43      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.54      0.15      0.23       970\n",
      "     disgust       1.00      0.17      0.29       107\n",
      "        fear       0.47      0.22      0.30      1015\n",
      "       happy       0.39      0.81      0.52      1824\n",
      "     neutral       0.40      0.32      0.35      1260\n",
      "         sad       0.35      0.29      0.32      1226\n",
      "    surprise       0.67      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.55      0.35      0.37      7178\n",
      "weighted avg       0.46      0.42      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.56      0.14      0.23       970\n",
      "     disgust       1.00      0.18      0.30       107\n",
      "        fear       0.52      0.22      0.31      1015\n",
      "       happy       0.38      0.81      0.52      1824\n",
      "     neutral       0.42      0.33      0.37      1260\n",
      "         sad       0.38      0.32      0.34      1226\n",
      "    surprise       0.69      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.36      0.38      7178\n",
      "weighted avg       0.47      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.15      0.22       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.43      0.22      0.29      1015\n",
      "       happy       0.40      0.76      0.52      1824\n",
      "     neutral       0.35      0.30      0.33      1260\n",
      "         sad       0.34      0.30      0.32      1226\n",
      "    surprise       0.67      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.51      0.35      0.37      7178\n",
      "weighted avg       0.42      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.53      0.15      0.23       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.51      0.22      0.30      1015\n",
      "       happy       0.39      0.80      0.53      1824\n",
      "     neutral       0.39      0.32      0.35      1260\n",
      "         sad       0.35      0.31      0.33      1226\n",
      "    surprise       0.68      0.54      0.60       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.55      0.36      0.38      7178\n",
      "weighted avg       0.46      0.42      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.61      0.14      0.22       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.54      0.22      0.31      1015\n",
      "       happy       0.39      0.83      0.53      1824\n",
      "     neutral       0.41      0.32      0.36      1260\n",
      "         sad       0.38      0.32      0.35      1226\n",
      "    surprise       0.70      0.55      0.61       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.37      0.39      7178\n",
      "weighted avg       0.48      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.40      0.15      0.22       970\n",
      "     disgust       1.00      0.19      0.31       107\n",
      "        fear       0.42      0.22      0.29      1015\n",
      "       happy       0.40      0.76      0.53      1824\n",
      "     neutral       0.35      0.31      0.33      1260\n",
      "         sad       0.36      0.32      0.34      1226\n",
      "    surprise       0.68      0.51      0.58       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.52      0.35      0.37      7178\n",
      "weighted avg       0.43      0.41      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.54      0.15      0.23       970\n",
      "     disgust       1.00      0.20      0.33       107\n",
      "        fear       0.50      0.23      0.32      1015\n",
      "       happy       0.39      0.81      0.53      1824\n",
      "     neutral       0.39      0.31      0.35      1260\n",
      "         sad       0.37      0.32      0.34      1226\n",
      "    surprise       0.70      0.54      0.61       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.37      0.39      7178\n",
      "weighted avg       0.47      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.60      0.14      0.23       970\n",
      "     disgust       1.00      0.21      0.34       107\n",
      "        fear       0.52      0.23      0.32      1015\n",
      "       happy       0.39      0.83      0.53      1824\n",
      "     neutral       0.41      0.30      0.35      1260\n",
      "         sad       0.38      0.32      0.34      1226\n",
      "    surprise       0.70      0.53      0.60       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.37      0.39      7178\n",
      "weighted avg       0.48      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.15      0.22       970\n",
      "     disgust       1.00      0.13      0.23       107\n",
      "        fear       0.43      0.22      0.29      1015\n",
      "       happy       0.40      0.77      0.52      1824\n",
      "     neutral       0.36      0.31      0.33      1260\n",
      "         sad       0.35      0.31      0.33      1226\n",
      "    surprise       0.66      0.53      0.59       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.52      0.35      0.36      7178\n",
      "weighted avg       0.43      0.41      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.56      0.15      0.24       970\n",
      "     disgust       1.00      0.16      0.27       107\n",
      "        fear       0.48      0.22      0.30      1015\n",
      "       happy       0.39      0.82      0.53      1824\n",
      "     neutral       0.40      0.32      0.36      1260\n",
      "         sad       0.39      0.33      0.36      1226\n",
      "    surprise       0.70      0.55      0.61       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.56      0.36      0.38      7178\n",
      "weighted avg       0.47      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.58      0.13      0.22       970\n",
      "     disgust       1.00      0.15      0.26       107\n",
      "        fear       0.52      0.21      0.30      1015\n",
      "       happy       0.39      0.83      0.53      1824\n",
      "     neutral       0.42      0.32      0.36      1260\n",
      "         sad       0.38      0.32      0.35      1226\n",
      "    surprise       0.70      0.54      0.61       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.36      0.38      7178\n",
      "weighted avg       0.48      0.43      0.40      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.15      0.23       970\n",
      "     disgust       1.00      0.13      0.23       107\n",
      "        fear       0.42      0.20      0.27      1015\n",
      "       happy       0.39      0.79      0.52      1824\n",
      "     neutral       0.39      0.32      0.35      1260\n",
      "         sad       0.35      0.28      0.31      1226\n",
      "    surprise       0.65      0.52      0.58       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.52      0.34      0.36      7178\n",
      "weighted avg       0.43      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.55      0.13      0.22       970\n",
      "     disgust       1.00      0.15      0.26       107\n",
      "        fear       0.49      0.19      0.28      1015\n",
      "       happy       0.38      0.83      0.52      1824\n",
      "     neutral       0.40      0.32      0.35      1260\n",
      "         sad       0.37      0.29      0.33      1226\n",
      "    surprise       0.66      0.53      0.59       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.55      0.35      0.36      7178\n",
      "weighted avg       0.46      0.42      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.62      0.12      0.21       970\n",
      "     disgust       1.00      0.17      0.29       107\n",
      "        fear       0.53      0.20      0.29      1015\n",
      "       happy       0.38      0.84      0.52      1824\n",
      "     neutral       0.41      0.32      0.36      1260\n",
      "         sad       0.39      0.30      0.34      1226\n",
      "    surprise       0.65      0.53      0.58       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.35      0.37      7178\n",
      "weighted avg       0.48      0.43      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.15      0.23       970\n",
      "     disgust       1.00      0.13      0.23       107\n",
      "        fear       0.42      0.20      0.27      1015\n",
      "       happy       0.39      0.79      0.52      1824\n",
      "     neutral       0.39      0.32      0.35      1260\n",
      "         sad       0.35      0.28      0.31      1226\n",
      "    surprise       0.65      0.52      0.58       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.52      0.34      0.36      7178\n",
      "weighted avg       0.43      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.55      0.13      0.22       970\n",
      "     disgust       1.00      0.15      0.26       107\n",
      "        fear       0.49      0.19      0.28      1015\n",
      "       happy       0.38      0.83      0.52      1824\n",
      "     neutral       0.40      0.32      0.35      1260\n",
      "         sad       0.37      0.29      0.33      1226\n",
      "    surprise       0.66      0.53      0.59       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.55      0.35      0.36      7178\n",
      "weighted avg       0.46      0.42      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.62      0.12      0.21       970\n",
      "     disgust       1.00      0.17      0.29       107\n",
      "        fear       0.53      0.20      0.29      1015\n",
      "       happy       0.38      0.84      0.52      1824\n",
      "     neutral       0.41      0.32      0.36      1260\n",
      "         sad       0.39      0.30      0.34      1226\n",
      "    surprise       0.65      0.53      0.58       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.57      0.35      0.37      7178\n",
      "weighted avg       0.48      0.43      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Accuracy: 0.41\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.46      0.14      0.22       970\n",
      "     disgust       1.00      0.07      0.12       107\n",
      "        fear       0.44      0.21      0.29      1015\n",
      "       happy       0.39      0.79      0.52      1824\n",
      "     neutral       0.38      0.32      0.34      1260\n",
      "         sad       0.34      0.28      0.30      1226\n",
      "    surprise       0.65      0.49      0.56       776\n",
      "\n",
      "    accuracy                           0.41      7178\n",
      "   macro avg       0.52      0.33      0.34      7178\n",
      "weighted avg       0.43      0.41      0.38      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.42\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.56      0.13      0.21       970\n",
      "     disgust       1.00      0.08      0.16       107\n",
      "        fear       0.50      0.20      0.29      1015\n",
      "       happy       0.39      0.84      0.53      1824\n",
      "     neutral       0.40      0.32      0.35      1260\n",
      "         sad       0.36      0.29      0.32      1226\n",
      "    surprise       0.67      0.52      0.58       776\n",
      "\n",
      "    accuracy                           0.42      7178\n",
      "   macro avg       0.55      0.34      0.35      7178\n",
      "weighted avg       0.46      0.42      0.39      7178\n",
      "\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Accuracy: 0.43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.67      0.13      0.22       970\n",
      "     disgust       1.00      0.11      0.20       107\n",
      "        fear       0.53      0.20      0.29      1015\n",
      "       happy       0.38      0.85      0.53      1824\n",
      "     neutral       0.44      0.33      0.38      1260\n",
      "         sad       0.37      0.30      0.33      1226\n",
      "    surprise       0.67      0.52      0.59       776\n",
      "\n",
      "    accuracy                           0.43      7178\n",
      "   macro avg       0.58      0.35      0.36      7178\n",
      "weighted avg       0.49      0.43      0.40      7178\n",
      "\n",
      "\n",
      "Best Combination: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Best Accuracy: 0.44\n",
      "\n",
      "Total combinations: 81\n",
      "Best model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_random_forest(X_train, y_train, X_test, y_test, label_encoder):\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],  # Number of trees\n",
    "        'max_depth': [10, 20, None],     # Depth of each tree\n",
    "        'min_samples_split': [2, 5, 10], # Minimum samples for a split\n",
    "        'min_samples_leaf': [1, 2, 4]    # Minimum samples per leaf\n",
    "    }\n",
    "\n",
    "    best_combination = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    all_combinations = list(ParameterGrid(param_grid))\n",
    "    for combination in all_combinations:\n",
    "        print(combination)\n",
    "        rf_model = RandomForestClassifier(**combination, random_state=42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_combination = combination\n",
    "    \n",
    "    # Print the best combination\n",
    "    print(\"\\nBest Combination:\", best_combination)\n",
    "    print(f\"Best Accuracy: {best_accuracy:.2f}\")\n",
    "    print(\"\\nTotal combinations:\", len(all_combinations))\n",
    "\n",
    "    # Train the best model on the entire training set\n",
    "    best_model = RandomForestClassifier(**best_combination, random_state=42)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model\n",
    "    with open(\"random_forest_model_standardscaler_grisearch_pca_dump.pkl\", \"wb\") as f:\n",
    "        dump(best_model, f, protocol=5)\n",
    "    print(\"Best model saved successfully!\")\n",
    "\n",
    "    return best_model, best_combination\n",
    "\n",
    "best_model, best_combination = train_and_evaluate_random_forest(X_train, y_train, X_test, y_test, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_predictions(best_model, X_test, y_test, label_encoder, X_original):\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    random_indices = np.random.randint(0, len(y_test), 5)\n",
    "    \n",
    "    for idx in random_indices:\n",
    "        original_image = X_original[idx].reshape(48, 48)  # Reshape to 48x48\n",
    "        plt.imshow(original_image, cmap='gray')\n",
    "        plt.title(f\"True: {label_encoder.inverse_transform([y_test[idx]])[0]}, \"\n",
    "                  f\"Predicted: {label_encoder.inverse_transform([y_pred[idx]])[0]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "visualize_predictions(best_model, X_test, y_test, label_encoder, X_original)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
