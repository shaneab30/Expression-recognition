{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04468185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils as vutils\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14193979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved hyperparameters\n",
    "BATCH_SIZE = 128  # Increased batch size for better statistics\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 1  # Grayscale\n",
    "LATENT_DIM = 100\n",
    "EPOCHS = 50  # More epochs for better convergence\n",
    "LR_G = 1e-4  # Separate learning rates\n",
    "LR_D = 4e-4  # Discriminator learns faster\n",
    "BETAS = (0.5, 0.999)  # Adam optimizer parameters\n",
    "N_CRITIC = 5  # Train discriminator more frequently for stability\n",
    "LABEL_SMOOTHING = 0.9  # Prevent discriminator overconfidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ba671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device and ensure reproducibility\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Enhanced data loading with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Grayscale(num_output_channels=CHANNELS),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Grayscale(num_output_channels=CHANNELS),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    \"D:/projects/machine learning/Expression-recognition/jonathanheix dataset/images/train\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,  # Increased workers for faster loading\n",
    "    pin_memory=True,\n",
    "    drop_last=True  # Avoid issues with small last batch\n",
    ")\n",
    "\n",
    "val_data = datasets.ImageFolder(\n",
    "    \"D:/projects/machine learning/Expression-recognition/jonathanheix dataset/images/validation\",\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral Normalization for stability\n",
    "class SpectralNorm:\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            return hasattr(self.module, f'{self.name}_u')\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "        \n",
    "        u = nn.Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
    "        v = nn.Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
    "        u.data = F.normalize(u.data, dim=0)\n",
    "        v.data = F.normalize(v.data, dim=0)\n",
    "        \n",
    "        setattr(self.module, f'{self.name}_u', u)\n",
    "        setattr(self.module, f'{self.name}_v', v)\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, f'{self.name}_u')\n",
    "        v = getattr(self.module, f'{self.name}_v')\n",
    "        w = getattr(self.module, self.name)\n",
    "        \n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = F.normalize(torch.mv(torch.t(w.view(height, -1).data), u.data), dim=0)\n",
    "            u.data = F.normalize(torch.mv(w.view(height, -1).data, v.data), dim=0)\n",
    "            \n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        self._update_u_v()\n",
    "        return self.module(*args, **kwargs)\n",
    "\n",
    "def spectral_norm(module):\n",
    "    return SpectralNorm(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79655512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Generator with residual connections and self-attention\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels, in_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels, in_channels, 3, 1, 1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.key = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, C, width, height = x.size()\n",
    "        proj_query = self.query(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
    "        proj_key = self.key(x).view(batch_size, -1, width * height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = F.softmax(energy, dim=-1)\n",
    "        proj_value = self.value(x).view(batch_size, -1, width * height)\n",
    "        \n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, width, height)\n",
    "        \n",
    "        return self.gamma * out + x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f26c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Initial projection\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.ConvTranspose2d(LATENT_DIM, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Upsampling layers with residual blocks\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            ResidualBlock(256)\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            ResidualBlock(128)\n",
    "        )\n",
    "        \n",
    "        # Self-attention at 16x16 resolution\n",
    "        self.attention = SelfAttention(128)\n",
    "        \n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            ResidualBlock(64)\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, CHANNELS, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.up3(x)\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Discriminator with spectral normalization and self-attention\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # 64x64 -> 32x32\n",
    "        self.layer1 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(CHANNELS, 64, 4, 2, 1, bias=False)),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 32x32 -> 16x16\n",
    "        self.layer2 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(64, 128, 4, 2, 1, bias=False)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Self-attention at 16x16 resolution\n",
    "        self.attention = SelfAttention(128)\n",
    "        \n",
    "        # 16x16 -> 8x8\n",
    "        self.layer3 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(128, 256, 4, 2, 1, bias=False)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 8x8 -> 4x4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(256, 512, 4, 2, 1, bias=False)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 4x4 -> 1x1\n",
    "        self.output = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(512, 1, 4, 1, 0, bias=False)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return self.output(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e573f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Print model architectures and parameter counts\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Generator parameters: {count_parameters(generator)}\")\n",
    "print(f\"Discriminator parameters: {count_parameters(discriminator)}\")\n",
    "\n",
    "# Setup optimizers with different learning rates\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=LR_G, betas=BETAS)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=LR_D, betas=BETAS)\n",
    "\n",
    "# Learning rate schedulers for better convergence\n",
    "g_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(g_optimizer, T_max=EPOCHS, eta_min=LR_G/10)\n",
    "d_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(d_optimizer, T_max=EPOCHS, eta_min=LR_D/10)\n",
    "\n",
    "# Loss functions\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "# Wasserstein loss for improved stability\n",
    "def wasserstein_loss(y_pred, y_true):\n",
    "    return torch.mean(y_true * y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f132d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced training function with gradient penalty and WGAN features\n",
    "def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n",
    "    \"\"\"Compute gradient penalty for improved WGAN training\"\"\"\n",
    "    batch_size = real_samples.size(0)\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1).to(device)\n",
    "    \n",
    "    # Create interpolated images\n",
    "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "    \n",
    "    # Calculate discriminator output for interpolated images\n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(d_interpolates).to(device),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    \n",
    "    # Calculate gradient penalty\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    \n",
    "    return gradient_penalty\n",
    "\n",
    "def train_epoch(generator, discriminator, dataloader, g_optimizer, d_optimizer, epoch):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    d_accs = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (real_images, _) in pbar:\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.to(device)\n",
    "        \n",
    "        # -------------------------\n",
    "        # Train Discriminator\n",
    "        # -------------------------\n",
    "        for _ in range(N_CRITIC):\n",
    "            discriminator.zero_grad()\n",
    "            \n",
    "            # Real images\n",
    "            label_real = torch.full((batch_size, 1, 1, 1), LABEL_SMOOTHING, device=device)  # Label smoothing\n",
    "            output_real = discriminator(real_images)\n",
    "            d_loss_real = bce_loss(output_real, label_real)\n",
    "            \n",
    "            # Fake images\n",
    "            z = torch.randn(batch_size, LATENT_DIM, 1, 1, device=device)\n",
    "            fake_images = generator(z).detach()\n",
    "            label_fake = torch.zeros(batch_size, 1, 1, 1, device=device)\n",
    "            output_fake = discriminator(fake_images)\n",
    "            d_loss_fake = bce_loss(output_fake, label_fake)\n",
    "            \n",
    "            # Gradient penalty for stability\n",
    "            gp = 0.1 * compute_gradient_penalty(discriminator, real_images, fake_images)\n",
    "            \n",
    "            # Combined loss with regularization\n",
    "            d_loss = d_loss_real + d_loss_fake + gp\n",
    "            \n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy for monitoring\n",
    "            pred_real = (output_real > 0.5).float()\n",
    "            pred_fake = (output_fake < 0.5).float()\n",
    "            acc = 0.5 * (torch.mean(pred_real) + torch.mean(pred_fake))\n",
    "            d_accs.append(acc.item())\n",
    "        \n",
    "        # -------------------------\n",
    "        # Train Generator\n",
    "        # -------------------------\n",
    "        generator.zero_grad()\n",
    "        \n",
    "        # Generate new fake images\n",
    "        z = torch.randn(batch_size, LATENT_DIM, 1, 1, device=device)\n",
    "        fake_images = generator(z)\n",
    "        \n",
    "        # Use feature matching loss: matching intermediate layer activations\n",
    "        label_real = torch.ones(batch_size, 1, 1, 1, device=device)\n",
    "        output_fake = discriminator(fake_images)\n",
    "        g_loss = bce_loss(output_fake, label_real)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_description(f\"[{epoch+1}/{EPOCHS}] D: {d_loss.item():.4f}, G: {g_loss.item():.4f}, Acc: {np.mean(d_accs):.4f}\")\n",
    "    \n",
    "    return np.mean(g_losses), np.mean(d_losses), np.mean(d_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced evaluation function\n",
    "def evaluate(generator, discriminator, dataloader, device):\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    d_accs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for real_images, _ in dataloader:\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images = real_images.to(device)\n",
    "            \n",
    "            # Real images\n",
    "            label_real = torch.ones(batch_size, 1, 1, 1, device=device)\n",
    "            output_real = discriminator(real_images)\n",
    "            d_loss_real = bce_loss(output_real, label_real)\n",
    "            \n",
    "            # Fake images\n",
    "            z = torch.randn(batch_size, LATENT_DIM, 1, 1, device=device)\n",
    "            fake_images = generator(z)\n",
    "            label_fake = torch.zeros(batch_size, 1, 1, 1, device=device)\n",
    "            output_fake = discriminator(fake_images)\n",
    "            \n",
    "            d_loss_fake = bce_loss(output_fake, label_fake)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            \n",
    "            # Generator loss\n",
    "            label_ones = torch.ones(batch_size, 1, 1, 1, device=device)\n",
    "            g_loss = bce_loss(output_fake, label_ones)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            pred_real = (output_real > 0.5).float()\n",
    "            pred_fake = (output_fake < 0.5).float()\n",
    "            acc = 0.5 * (torch.mean(pred_real) + torch.mean(pred_fake))\n",
    "            \n",
    "            g_losses.append(g_loss.item())\n",
    "            d_losses.append(d_loss.item())\n",
    "            d_accs.append(acc.item())\n",
    "    \n",
    "    return np.mean(g_losses), np.mean(d_losses), np.mean(d_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ac92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed noise for consistent evaluation\n",
    "fixed_noise = torch.randn(64, LATENT_DIM, 1, 1, device=device)\n",
    "\n",
    "# Setup directories for saving models and images\n",
    "os.makedirs(\"gan_images\", exist_ok=True)\n",
    "os.makedirs(\"gan_models\", exist_ok=True)\n",
    "\n",
    "# Initialize tracking metrics\n",
    "train_g_losses, train_d_losses, train_accuracies = [], [], []\n",
    "val_g_losses, val_d_losses, val_accuracies = [], [], []\n",
    "best_val_acc = 0\n",
    "best_fid = float('inf')\n",
    "\n",
    "# Training loop with early stopping\n",
    "patience = 7  # Early stopping patience\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training\n",
    "    g_loss, d_loss, train_acc = train_epoch(\n",
    "        generator, discriminator, train_loader,\n",
    "        g_optimizer, d_optimizer, epoch\n",
    "    )\n",
    "    train_g_losses.append(g_loss)\n",
    "    train_d_losses.append(d_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    # Validation\n",
    "    val_g_loss, val_d_loss, val_acc = evaluate(\n",
    "        generator, discriminator, val_loader, device\n",
    "    )\n",
    "    val_g_losses.append(val_g_loss)\n",
    "    val_d_losses.append(val_d_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Generate and save sample images\n",
    "    with torch.no_grad():\n",
    "        fake = generator(fixed_noise)\n",
    "        vutils.save_image(fake, f\"gan_images/fake_epoch_{epoch+1}.png\", normalize=True)\n",
    "    \n",
    "    # Save best model based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "            'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "        }, 'gan_models/best_model.pth')\n",
    "        print(f\"Saved best model with val_acc: {val_acc:.4f}\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "    \n",
    "    # Step learning rate schedulers\n",
    "    g_scheduler.step()\n",
    "    d_scheduler.step()\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n",
    "    print(f\"Train - G_loss: {g_loss:.4f}, D_loss: {d_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val - G_loss: {val_g_loss:.4f}, D_loss: {val_d_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "    print(f\"Learning rates - G: {g_optimizer.param_groups[0]['lr']:.6f}, D: {d_optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'generator_state_dict': generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "            'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "        }, f'gan_models/checkpoint_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    # Early stopping\n",
    "    if no_improve >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_g_losses, label='Generator Train')\n",
    "plt.plot(val_g_losses, label='Generator Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Generator Loss')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_d_losses, label='Discriminator Train')\n",
    "plt.plot(val_d_losses, label='Discriminator Val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Discriminator Loss')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(train_accuracies, label='Train')\n",
    "plt.plot(val_accuracies, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Discriminator Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gan_images/training_curves.png')\n",
    "plt.close()\n",
    "\n",
    "# Load the best model for inference\n",
    "best_model = torch.load('gan_models/best_model.pth')\n",
    "generator.load_state_dict(best_model['generator_state_dict'])\n",
    "discriminator.load_state_dict(best_model['discriminator_state_dict'])\n",
    "\n",
    "print(f\"Training completed. Best validation accuracy: {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f794da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate samples with the best model\n",
    "def generate_samples(n_samples=25, z_dim=LATENT_DIM):\n",
    "    \"\"\"Generate and save samples from the best model\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(n_samples, z_dim, 1, 1, device=device)\n",
    "        samples = generator(z)\n",
    "        vutils.save_image(samples, f\"gan_images/final_samples.png\", nrow=5, normalize=True)\n",
    "    return samples\n",
    "\n",
    "# Generate final samples\n",
    "generate_samples(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
