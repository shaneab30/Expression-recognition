{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/shaneab/Projects/Machine Learning/Expression recognition/fer20131.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting pixel data from pixel column\n",
    "# convert it to integer\n",
    "# drop original pixel column\n",
    "# add all pixels as individual column\n",
    "\n",
    "pixels = []\n",
    "\n",
    "for pix in dataset.pixels:\n",
    "    values = [int(i) for i in pix.split()]\n",
    "    pixels.append(values)\n",
    "\n",
    "pixels = np.array(pixels)\n",
    "\n",
    "# rescaling pixel values\n",
    "pixels = pixels/255.0\n",
    "\n",
    "\n",
    "dataset.drop(columns=['pixels'], axis=1, inplace=True)\n",
    "\n",
    "pix_cols = [] # for keeping track of column names\n",
    "\n",
    "# add each pixel value as a column\n",
    "for i in range(pixels.shape[1]):\n",
    "    name = f'pixel_{i}'\n",
    "    pix_cols.append(name)\n",
    "    dataset[name] = pixels[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {\n",
    "    0: 'Angry', \n",
    "    1: 'Disgust', \n",
    "    2: 'Fear', \n",
    "    3: 'Happy', \n",
    "    4: 'Sad', \n",
    "    5: 'Surprise', \n",
    "    6: 'Neutral'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERDataset(Dataset):\n",
    "    '''\n",
    "        Parse raw data to form a Dataset of (X, y).\n",
    "    '''\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.tensor_transform = T.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = int(row['emotion'])\n",
    "        img = np.copy(row[pix_cols].values.reshape(48, 48))\n",
    "        img.setflags(write=True)\n",
    "\n",
    "        if self.transform:\n",
    "            img = Image.fromarray(img)\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = self.tensor_transform(img)\n",
    "\n",
    "        return img, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 8))\n",
    "sns.countplot(x=dataset.emotion)\n",
    "_ = plt.title('Emotion Distribution')\n",
    "_ = plt.xticks(ticks=range(0, 7), labels=[emotions[i] for i in range(0, 7)], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transformations() -> (object, object):\n",
    "    '''\n",
    "        Return transformations to be applied.\n",
    "        Input:\n",
    "            None\n",
    "        Output:\n",
    "            train_tfms: transformations to be applied on the training set\n",
    "            valid_tfms: transformations to be applied on the validation or test set\n",
    "    '''\n",
    "\n",
    "    train_trans = [      \n",
    "        T.RandomCrop(48, padding=4, padding_mode='reflect'),     \n",
    "        T.RandomRotation(15),\n",
    "        T.RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.01, 0.12),\n",
    "            shear=(0.01, 0.03),\n",
    "        ),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "    ]\n",
    "\n",
    "    val_trans = [\n",
    "        T.ToTensor(), \n",
    "    ]\n",
    "\n",
    "    train_transformations = T.Compose(train_trans)\n",
    "    valid_tfms = T.Compose(val_trans)\n",
    "\n",
    "    return train_transformations, valid_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataset(dataframe: object, transformation: bool=True) -> (object, object):\n",
    "    '''\n",
    "        Returns an object on FERDataset class\n",
    "        Input:\n",
    "            dataframe: object -> DataFrame object containing the whole data\n",
    "            transformation: bool [optional] ->  Apply transformations\n",
    "    '''\n",
    "\n",
    "    # extracts rows specific to Training, PublicTest\n",
    "    dataframe = dataframe.loc[dataframe.Usage.isin(['Training', 'PublicTest'])]\n",
    "    # drop Usage column as it's no longer needed    \n",
    "    dataframe = dataframe.drop('Usage', axis=1)\n",
    "\n",
    "    # split dataset into training and validation set\n",
    "    np.random.seed(42)  \n",
    "    msk = np.random.rand(len(dataframe)) < 0.8\n",
    "\n",
    "    train_df = dataframe[msk].reset_index()\n",
    "    val_df = dataframe[~msk].reset_index()\n",
    "\n",
    "    # get transformations\n",
    "    if transformation:\n",
    "        train_tfms, valid_tfms = image_transformations()\n",
    "    else:\n",
    "        train_tfms, valid_tfms = None, None\n",
    "\n",
    "    # fetch dataset\n",
    "    train_ds = FERDataset(dataframe, transform=train_tfms)\n",
    "    val_ds = FERDataset(dataframe, transform=valid_tfms)\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataloader(dataframe: object, transformation=True, batch_size: int=64) -> (object, object):\n",
    "    '''\n",
    "        Returns train and test dataloaders.\n",
    "        Input:\n",
    "            dataframe: dataset DataFrame object\n",
    "            batch_size: [optional] int\n",
    "        Output:\n",
    "            train_dl: train dataloader object\n",
    "            valid_dl: validation dataloader object\n",
    "    '''\n",
    "    # fetech train and validation dataset\n",
    "    train_ds, valid_ds = get_train_dataset(dataframe, transformation=transformation)\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle=True, \n",
    "                     num_workers=3, pin_memory=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size*2, \n",
    "                    num_workers=2, pin_memory=True)\n",
    "    \n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataloader(dataframe: object, batch_size: int=128) -> object:\n",
    "    '''\n",
    "        Returns test set dataloaders.\n",
    "        Input:\n",
    "            dataframe: dataset DataFrame object\n",
    "            batch_size: [optional] int\n",
    "        Output:\n",
    "            test_dl: test dataloader object\n",
    "    '''\n",
    "    # extracts rows specific to PrivateTest\n",
    "    test_df = dataframe.loc[dataset.Usage.isin(['PrivateTest'])]\n",
    "\n",
    "    # drop Usage column as it's no longer needed\n",
    "    test_df = test_df.drop('Usage', axis=1)\n",
    "\n",
    "    # get transformations same as validation set\n",
    "    _, valid_tfms = image_transformations()\n",
    "    \n",
    "    test_dataset = FERDataset(test_df, transform=valid_tfms)\n",
    "    test_dl = DataLoader(test_dataset, batch_size, num_workers=3 , pin_memory=True)\n",
    "\n",
    "    # move loader to GPU (class defined ahead)\n",
    "    test_dl = DeviceDataLoader(test_dl, device)\n",
    "    return test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_un, _ = get_train_dataloader(dataset, transformation=False)\n",
    "train_dl, _ = get_train_dataloader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in train_dl_un:\n",
    "    print('images.shape:', images.shape)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(make_grid(images, nrow=8).permute((1, 2, 0))) # move the channel dimension\n",
    "    break\n",
    "\n",
    "_ = plt.suptitle(\"Images\", y=0.92, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in train_dl:\n",
    "    print('images.shape:', images.shape)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(make_grid(images, nrow=8).permute((1, 2, 0))) # move the channel dimension\n",
    "    break\n",
    "\n",
    "_ = plt.suptitle(\"Transformed Images\", y=0.92, fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
